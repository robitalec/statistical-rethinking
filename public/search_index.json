[["index.html", "Learning bayesian data analysis with Statistical Rethinking 1 Overview 1.1 Links 1.2 Seed", " Learning bayesian data analysis with Statistical Rethinking Alec L. Robitaille 2021-08-18 [updated: 2021-09-08] 1 Overview 1.1 Links Link: https://github.com/rmcelreath/statrethinking_winter2019 1.1.1 Adaptations Stan+R: https://vincentarelbundock.github.io/rethinking2/ tidy+rethinking: https://david-salazar.github.io/2020/04/19/statistical-rethinking-week-1/ brms+tidy: https://bookdown.org/content/4857/ 1.1.2 Etc https://chi-feng.github.io/mcmc-demo 1.2 Seed set.seed(42) "],["homework-week-1.html", "2 Homework: Week 1 2.1 Variables 2.2 Joint model 2.3 Question 1 2.4 Question 2 2.5 Question 3", " 2 Homework: Week 1 2021-08-18 [updated: 2021-09-08] 2.1 Variables N: fixed by experimenter p: Prior probability W: A probability distribution given the data. 2.2 Joint model W ~ Binomial(N , p) p ~ Uniform(0, 1) W is distributed binomially with N observations and probability p on each p is distributed uniformally at 1 2.3 Question 1 Suppose the globe tossing data (Chapter 2) had turned out to be 8 water in 15 tosses. Construct the posterior distribution, using grid approximation. Use the same flat prior as in the book. # Size of grid for grid approximation gridsize &lt;- 1000 # Prior grid prior_grid &lt;- seq(0, 1, length.out = gridsize) # Prior probability (all 1) prior_prob &lt;- rep(1, gridsize) # Data probability # given 4/15, using binomial distribution data_prob &lt;- dbinom(8, 15, prob = prior_grid) # Calculate the posterior numerator by multiplying prior and data probability posterior_num &lt;- prior_prob * data_prob # Standardize by sum of posterior numerator posterior &lt;- posterior_num / sum(posterior_num) # Save for later posterior_1 &lt;- posterior plot(posterior, type = &#39;l&#39;) # Sample from posterior samples &lt;- sample(prior_grid, size = gridsize, prob = posterior, replace = TRUE) mean(samples) ## [1] 0.536975 PI(samples, .99) ## 1% 100% ## 0.2652452 0.8048348 2.4 Question 2 Start over in 1, but now use a prior that is zero below p = 0.5 and a constant above p = 0.5. This corresponds to prior information that a majority of the Earth’s surface is water. What difference does the better prior make? # Size of grid for grid approximation gridsize &lt;- 1000 # Prior grid prior_grid &lt;- seq(0, 1, length.out = gridsize) # Prior probability (all 1 above 0.5, all 0 below) prior_prob &lt;- c(rep(0, gridsize / 2), rep(1, gridsize / 2)) # Data probability # given 4/15, using binomial distribution data_prob &lt;- dbinom(4, 15, prob = prior_grid) # Calculate the posterior numerator by multiplying prior and data probability posterior_num &lt;- prior_prob * data_prob # Standardize by sum of posterior numerator posterior &lt;- posterior_num / sum(posterior_num) # Save for later posterior_2 &lt;- posterior plot(posterior, type = &#39;l&#39;) # Sample from posterior samples &lt;- sample(prior_grid, size = gridsize, prob = posterior, replace = TRUE) mean(samples) ## [1] 0.5469029 PI(samples, .99) ## 1% 100% ## 0.5005005 0.7157407 Narrower curve, higher max, all zeroes before 0.5 2.5 Question 3 For the posterior distribution from 2, compute 89% percentile and HPDI intervals. Compare the widths of these intervals. Which is wider? Why? If you had only the information in the interval, what might you misunderstand about the shape of the posterior distribution? library(rethinking) library(ggplot2) library(data.table) # Calculate Percentile Interval at 89% percent_interval &lt;- PI(posterior, prob = 0.89) percent_interval ## 5% 94% ## 0.000000000 0.007254589 # Calculate Highest Posterior Density at 89% highest_post_dens &lt;- HPDI(posterior, prob = 0.89) highest_post_dens ## |0.89 0.89| ## 0.000000000 0.002523398 "],["homework-week-2.html", "3 Homework: Week 2 3.1 Question 1 3.2 Question 2 3.3 Homework: Question 3", " 3 Homework: Week 2 2021-08-24 [updated: 2021-09-08] 3.1 Question 1 The weights listed below were recorded in the !Kung census, but heights were not recorded for these individuals. Provide predicted heights and 89% compatibility intervals for each of these individuals. That is, fill in the table below, using model-based predictions. Individual, weight, expected height, 89% interval 1, 45,,, 2, 40,,, 3, 65,,, 4, 31,,, 5, 53,,, Model: \\(h_{i} \\sim \\text{Normal}(\\mu_{i}, \\sigma)\\) \\(\\mu_{i} = \\alpha + \\beta(x_{i} - \\bar{x})\\) \\(\\alpha \\sim \\text{Normal}(178, 20)\\) \\(\\beta \\sim \\text{Log-Normal}(0, 1)\\) \\(\\sigma \\sim \\text{Uniform}(0, 50)\\) library(rethinking) library(data.table) library(ggplot2) library(tidybayes) theme_set(theme_bw()) data(Howell1) d &lt;- Howell1[Howell1$age &gt;= 18,] m &lt;- quap( alist( height ~ dnorm(mu, sigma), mu &lt;- a + b * (weight - mean(d$weight)), a ~ dnorm(178, 20), b ~ dnorm(0, 1), sigma ~ dunif(0, 50) ), data = d ) precis(m) ## mean sd 5.5% 94.5% ## a 154.6014208 0.27030782 154.1694167 155.0334249 ## b 0.9034427 0.04189141 0.8364922 0.9703933 ## sigma 5.0718837 0.19115501 4.7663811 5.3773863 Simulate: # Set weights to simulate for weights &lt;- data.table(weight = c(45, 40, 65, 31, 54), id = as.character(seq(1, 5))) simmed &lt;- sim(m, list(weight = weights$weight), n = 1e3) # Tidy DT &lt;- melt(as.data.table(simmed), measure.vars = paste0(&#39;V&#39;, 1:5), value.name = &#39;height&#39;, variable.name = &#39;id&#39;) DT[, id := gsub(&#39;V&#39;, &#39;&#39;, id)] DT[weights, weight := weight, on = &#39;id&#39;] # Plot ggplot(DT, aes(height)) + stat_halfeye(.width = .89) + facet_wrap(~id) 3.2 Question 2 Model the relationship between height (cm) and the natural logarithm of weight (log-kg): log(weight). Use the entire Howell1 data frame, all 544 rows, adults and non-adults. Use any model type from Chapter 4 that you think useful: an ordinary linear regression, a polynomial or a spline. Plot the posterior predictions against the raw data library(rethinking) library(data.table) library(ggplot2) library(tidybayes) theme_set(theme_bw()) data(Howell1) d &lt;- Howell1 d$logweight &lt;- log(d$weight) m1 &lt;- quap( alist( height ~ dnorm(mu, sigma), mu &lt;- a + b * (logweight - mean(d$logweight)), a ~ dnorm(178, 20), b ~ dnorm(0, 1), sigma ~ dunif(0, 50) ), data = d ) sim_x &lt;- log(1:60) simmed &lt;- sim(m1, list(logweight = sim_x)) # Tidy DT &lt;- melt(as.data.table(simmed), value.name = &#39;height&#39;, variable.name = &#39;x&#39;) ## Warning in melt.data.table(as.data.table(simmed), value.name = &quot;height&quot;, : ## id.vars and measure.vars are internally guessed when both are &#39;NULL&#39;. All ## non-numeric/integer/logical type columns are considered id.vars, which in this ## case are columns []. Consider providing at least one of &#39;id&#39; or &#39;measure&#39; vars ## in future. DT[data.table(sim_x, x = paste0(&#39;V&#39;, 1:60)), logweight := sim_x, on = &#39;x&#39;] DT[, meanheight := mean(height), by = logweight] DT[, low := PI(height)[1], by = logweight] DT[, high := PI(height)[2], by = logweight] # Plot ggplot(DT) + geom_ribbon(aes(x = exp(logweight), ymin = low, ymax = high), fill = &#39;grey&#39;) + geom_point(aes(exp(logweight), height), data = d, color = &#39;lightblue&#39;, alpha = 0.8) + geom_line(aes(exp(logweight), meanheight)) Using the dlnorm, prior of a Log normal distribution on beta m2 &lt;- quap( alist( height ~ dnorm(mu, sigma), mu &lt;- a + b * (logweight - mean(d$logweight)), a ~ dnorm(178, 20), b ~ dlnorm(0, 1), sigma ~ dunif(0, 50) ), data = d ) sim_x &lt;- log(1:60) simmed &lt;- sim(m2, list(logweight = sim_x)) # Tidy DT &lt;- melt(as.data.table(simmed), value.name = &#39;height&#39;, variable.name = &#39;x&#39;) ## Warning in melt.data.table(as.data.table(simmed), value.name = &quot;height&quot;, : ## id.vars and measure.vars are internally guessed when both are &#39;NULL&#39;. All ## non-numeric/integer/logical type columns are considered id.vars, which in this ## case are columns []. Consider providing at least one of &#39;id&#39; or &#39;measure&#39; vars ## in future. DT[data.table(sim_x, x = paste0(&#39;V&#39;, 1:60)), logweight := sim_x, on = &#39;x&#39;] DT[, meanheight := mean(height), by = logweight] DT[, low := PI(height)[1], by = logweight] DT[, high := PI(height)[2], by = logweight] # Plot ggplot(DT) + geom_ribbon(aes(x = exp(logweight), ymin = low, ymax = high), fill = &#39;grey&#39;) + geom_point(aes(exp(logweight), height), data = d, color = &#39;lightblue&#39;, alpha = 0.8) + geom_line(aes(exp(logweight), meanheight)) 3.3 Homework: Question 3 Set up: library(rethinking) library(data.table) library(ggplot2) library(tidybayes) theme_set(theme_bw()) data(Howell1) d &lt;- Howell1 d$weight_s &lt;- scale(d$weight) d$weight_s2 &lt;- scale(d$weight) ^ 2 m &lt;- quap( alist( height ~ dnorm(mu, sigma), mu ~ a + b1 * weight_s + b2 * weight_s2, a ~ dnorm(178, 20), b1 ~ dlnorm(0, 1), b2 ~ dnorm(0, 1), sigma ~ dunif(0, 50) ), data = d ) n &lt;- 20 sim_x &lt;- seq(min(d$weight_s), max(d$weight_s), length.out = n) linked &lt;- link( m, data = list(weight_s = sim_x, weight_s2 = sim_x ^ 2), post = extract.prior(m) )[1:50,] plot(NULL, xlim = range(sim_x), ylim = range(linked) + c(-10, 10)) apply(linked, 1, FUN = function(x) lines(sim_x, x)) ## NULL m &lt;- quap( alist( height ~ dnorm(mu, sigma), mu ~ a + b1 * weight_s + b2 * weight_s2, a ~ dnorm(178, 20), b1 ~ dlnorm(0, 1), b2 ~ dnorm(0, 10), sigma ~ dunif(0, 50) ), data = d ) n &lt;- 20 sim_x &lt;- seq(min(d$weight_s), max(d$weight_s), length.out = n) linked &lt;- link( m, data = list(weight_s = sim_x, weight_s2 = sim_x ^ 2), post = extract.prior(m) )[1:50,] plot(NULL, xlim = range(sim_x), ylim = range(linked) + c(-10, 10)) apply(linked, 1, FUN = function(x) lines(sim_x, x)) ## NULL "],["homework-week-3.html", "4 Homework: Week 3 4.1 Overview 4.2 Question 1 4.3 Question 2 4.4 Question 3", " 4 Homework: Week 3 2021-08-25 [updated: 2021-09-08] 4.1 Overview All three problems below are based on the same data. The data in data(foxes) are 116 foxes from 30 different urban groups in England. These foxes are like street gangs. Group size varies from 2 to 8 individuals. Each group maintains its own (almost exclusive) urban territory. Some territories are larger than others. The area variable encodes this information. Some territories also have more avgfood than others. We want to model the weight of each fox. For the problems below, assume this DAG 4.1.1 Setup # Packages library(ggdag) ## ## Attaching package: &#39;ggdag&#39; ## The following object is masked from &#39;package:stats&#39;: ## ## filter library(dagitty) library(data.table) library(ggplot2) library(tidybayes) # DAG dag_plot &lt;- function(dag) { stat &lt;- node_status(dag, FALSE) stat$data$status[is.na(stat$data$status)] &lt;- &#39;intermediate&#39; ggplot(stat, aes(x = x, y = y, xend = xend, yend = yend)) + geom_dag_point(aes(color = status), alpha = 0.5, size = 15) + geom_dag_edges() + labs(color = &#39;&#39;) + geom_dag_text(color = &#39;black&#39;) + scale_color_manual(values = list(&#39;exposure&#39; = &#39;#35608DFF&#39;, &#39;outcome&#39; = &#39;#22A884FF&#39;, &#39;intermediate&#39; = &#39;grey50&#39;)) + theme_void() } dag &lt;- dagify( weight ~ groupsize + avgfood, groupsize ~ avgfood, avgfood ~ area, exposure = &#39;area&#39;, outcome = &#39;weight&#39; ) dag_plot(dag) 4.2 Question 1 Use a model to infer the total causal influence of area on weight. Would increasing the area available to each fox make it heavier (healthier)? You might want to standardize the variables. Regardless, use prior predictive simulation to show that your model’s prior predictions stay within the possible outcome range. 4.2.1 Workings Area on weight scale(weight) ~ dnorm(mu, sigma) mu &lt;- a + b * (scale(area)) a: intercept when weight and area are scaled, the expected intercept is 0 therefore a ~ dnorm(0, 0.5) b: beta, rate of change given one unit of increase in area b ~ dnorm(0, 1) sigma: standard deviation uniform prior sigma ~ dunif(0, 50) 4.2.2 Model library(rethinking) data(foxes) foxes$scale_area &lt;- scale(foxes$area) foxes$scale_weight &lt;- scale(foxes$weight) m1 &lt;- quap( alist( scale_weight ~ dnorm(mu, sigma), mu &lt;- a + bArea * scale_area, a ~ dnorm(0, 0.05), bArea ~ dnorm(0, 0.5), sigma ~ dunif(0, 50) ), data = foxes ) 4.2.3 Prior predictive simulation plot_link &lt;- function(DT, n) { data.table(DT)[sample(.N, n), plot(data.table(x = rep(c(-2, 2), .N), y = c(V1, V2)), type = &#39;l&#39;)] } prior &lt;- extract.prior(m1) l &lt;- link(m1, post = prior, data = list(scale_area = c(-2, 2))) plot_link(l, 20) ## NULL 4.2.4 Paths Interest: Area on Weight Paths Area -&gt; Avgfood -&gt; Weight Area -&gt; Avgfood -&gt; Groupsize -&gt; Weight Avgfood and Groupsize are pipes between Area and Weight. There are no backdoors or colliders. 4.2.5 Interpretation Would increasing the area available to each fox make it heavier (healthier)? bArea has a mean of 0.02, with compatibility intervals around 0. Therefore the model does not indicate a total causal influence of area on the weight. precis(m1) ## mean sd 5.5% 94.5% ## a -0.000001 0.044 -0.07 0.07 ## bArea 0.018844 0.091 -0.13 0.16 ## sigma 0.995497 0.065 0.89 1.10 post &lt;- extract.samples(m1) s &lt;- sim(m1, data = list(scale_area = c(-2, 2)), post = post) ggplot(data.table(s), aes(V1)) + stat_halfeye(.width = .89) 4.3 Question 2 Now infer the causal impact of adding food to a territory. Would this make foxes heavier? Which covariates do you need to adjust for to estimate the total causal influence of food? 4.3.1 Paths Interest: Food on weight Paths: Food -&gt; Weight Food -&gt; Groupsize -&gt; Weight Groupsize is a pipe between Area and Weight. There are no backdoors or colliders. 4.3.2 Model foxes$scale_avgfood &lt;- scale(foxes$avgfood) m2 &lt;- quap( alist( scale_weight ~ dnorm(mu, sigma), mu &lt;- a + bFood * scale_avgfood, a ~ dnorm(0, 0.05), bFood ~ dnorm(0, 0.5), sigma ~ dunif(0, 50) ), data = foxes ) precis(m2) ## mean sd 5.5% 94.5% ## a 0.0000018 0.044 -0.07 0.07 ## bFood -0.0241757 0.091 -0.17 0.12 ## sigma 0.9953723 0.065 0.89 1.10 post &lt;- extract.samples(m2) s &lt;- sim(m2, data = list(scale_avgfood = c(-2, 2)), post = post) ggplot(data.table(s), aes(V1)) + stat_halfeye(.width = .89) 4.3.3 Interpretation Would this make foxes heavier? Which covariates do you need to adjust for to estimate the total causal influence of food? bFood has a mean of -0.02, with compatibility intervals around 0. The model does not indicate a total causal influence of area on the weight. No covariates are needed to estiamte the total causal influence of food because there are no backdoors or colliders. 4.4 Question 3 Now infer the causal impact of group size. Which covariates do you need to adjust for? Looking at the posterior distribution of the resulting model, what do you think explains these data? That is, can you explain the estimates for all three problems? How do they go together? 4.4.1 Paths Interest: Group size on weight Paths: Groupsize -&gt; Weight Groupsize &lt;- Avgfood -&gt; Weight Avgfood is a collider between Groupsize and Weight. There is a backdoor on Groupsize and the path is closed. foxes$scale_groupsize &lt;- scale(foxes$groupsize) m3 &lt;- quap( alist( scale_weight ~ dnorm(mu, sigma), mu &lt;- a + bGroupsize * scale_groupsize + bFood * scale_avgfood, a ~ dnorm(0, 0.05), bGroupsize ~ dnorm(0, 0.5), bFood ~ dnorm(0, 0.5), sigma ~ dunif(0, 50) ), data = foxes ) precis(m3) ## mean sd 5.5% 94.5% ## a 0.00000062 0.043 -0.069 0.069 ## bGroupsize -0.57250071 0.180 -0.860 -0.285 ## bFood 0.47624205 0.180 0.189 0.763 ## sigma 0.94590281 0.062 0.846 1.046 DT &lt;- melt(data.table(extract.samples(m3))[, .(bGroupsize, bFood)]) ## Warning in melt.data.table(data.table(extract.samples(m3))[, .(bGroupsize, : ## id.vars and measure.vars are internally guessed when both are &#39;NULL&#39;. All ## non-numeric/integer/logical type columns are considered id.vars, which in this ## case are columns []. Consider providing at least one of &#39;id&#39; or &#39;measure&#39; vars ## in future. ggplot(DT) + geom_density(aes(value, fill = variable), alpha = 0.6) + theme_bw() + scale_fill_viridis_d(begin = 0.3, end = 0.8) 4.4.2 Interpretation Which covariates do you need to adjust for? Looking at the posterior distribution of the resulting model, what do you think explains these data? That is, can you explain the estimates for all three problems? How do they go together? The Avgfood covariate needs to be included since it is a collider between Groupsize and Weight. The mean and compatibility intervals of bFood are positive, while the mean and compatibility intervals of bGroupsize are negative. This indicates food’s positive relationship with weight could be buffered or interacting with the negative relationship of group size. Increased food leads to increased body weight, but more food also results in larger groups, which decreases the food availability. "],["homework-week-4.html", "5 Homework: Week 4 5.1 Question 1 5.2 Question 2 5.3 Question 3", " 5 Homework: Week 4 2021-08-30 [updated: 2021-09-08] 5.0.1 Setup # Packages library(ggdag) library(dagitty) library(data.table) library(ggplot2) library(tidybayes) # Functions dag_plot &lt;- function(dag) { stat &lt;- node_status(dag, FALSE) stat$data$status[is.na(stat$data$status)] &lt;- &#39;intermediate&#39; ggplot(stat, aes(x = x, y = y, xend = xend, yend = yend)) + geom_dag_point(aes(color = status), alpha = 0.5, size = 15) + geom_dag_edges() + labs(color = &#39;&#39;) + geom_dag_text(color = &#39;black&#39;) + scale_color_manual(values = list(&#39;exposure&#39; = &#39;#35608DFF&#39;, &#39;outcome&#39; = &#39;#22A884FF&#39;, &#39;intermediate&#39; = &#39;grey50&#39;)) + theme_void() } 5.1 Question 1 Consider three fictional Polynesian islands. On each there is a Royal Ornithologist charged by the king with surveying the birb population. They have each found the following proportions of 5 important birb species: # Data birds &lt;- matrix( c(0.2, 0.2, 0.2, 0.2, 0.2, 0.8, 0.1, 0.05, 0.025, 0.025, 0.05, 0.15, 0.7, 0.05, 0.05), nrow = 3, ncol = 5, byrow = TRUE ) dimnames(birds) &lt;- list(as.character(1:3), LETTERS[1:5]) birds ## A B C D E ## 1 0.20 0.20 0.20 0.200 0.200 ## 2 0.80 0.10 0.05 0.025 0.025 ## 3 0.05 0.15 0.70 0.050 0.050 First, compute the entropy of each island’s birb distribution. Interpret these entropy values DT &lt;- melt(data.table(birds, keep.rownames = &#39;island&#39;), id.vars = &#39;island&#39;, variable.name = &#39;id&#39;, value.name = &#39;proportion&#39;) # Entropy entropy &lt;- function(p) -sum(p * log(p)) DT[, .(entropy = entropy(proportion)), by = island] ## island entropy ## &lt;char&gt; &lt;num&gt; ## 1: 1 1.61 ## 2: 2 0.74 ## 3: 3 0.98 The information entropy describes the uncertainty in a distribution of probabilities given the average log-probability of an event (from Statistical Rethinking 7.2). Island 1 has the highest entropy, with the flat probability of 0.2 across 5 bird species. Island 2 has the lowest entropy, including species A with the highest overall proportion 0.8. Second, use each island’s birb distribution to predict the other two. This means to compute the K-L Divergence of each island from the others, treating each island as if it were a statistical model of the other islands. You should end up with 6 different K-L Divergence values. Which island predicts the others best? Why? divergence &lt;- function(p, q) sum(p * (log(p) - log(q))) z &lt;- CJ(p = DT$island, q = DT$island, unique = TRUE)[, row_id := .I] z[, div := divergence(DT[island == p, proportion], DT[island == q, proportion]), by = row_id] z[p != q] ## p q row_id div ## &lt;char&gt; &lt;char&gt; &lt;int&gt; &lt;num&gt; ## 1: 1 2 2 0.97 ## 2: 1 3 3 0.64 ## 3: 2 1 4 0.87 ## 4: 2 3 6 2.01 ## 5: 3 1 7 0.63 ## 6: 3 2 8 1.84 divergence(p, q) = “Average difference in log probability between the target (p) and the model (q)”. Model 1 predicts target 3 best (lowest divergence at 0.63) and target 2 best (lowest divergence at 0.87) because it has the highest entropy. Model 3 predicts target 1 best (lowest divergence at 0.64) because it has higher entropy than model 2. 5.2 Question 2 Recall the marriage, age, and happiness collider bias example from Chapter 6. Run models m6.9 and m6.10 again. 5.2.1 DAG dag &lt;- dagify( marriage ~ happiness, marriage ~ age, exposure = &#39;age&#39;, outcome = &#39;happiness&#39; ) dag_plot(dag) 5.2.2 Data library(rethinking) d &lt;- sim_happiness(seed = 1977, N_years = 1e3) d2 &lt;- d[d$age &gt; 17,] d2$A &lt;- (d2$age - 18) / (65 - 18) d2$mid &lt;- d2$married + 1 precis(d2) ## mean sd 5.5% 94.5% histogram ## age 41.5000000000000000 13.86 20.000 63.00 ▃▇▇▇▇▇▇▇▇▇ ## married 0.4072916666666667 0.49 0.000 1.00 ▇▁▁▁▁▁▁▁▁▅ ## happiness -0.0000000000000001 1.21 -1.789 1.79 ▇▅▇▅▅▇▅▇ ## A 0.5000000000000000 0.29 0.043 0.96 ▇▇▇▅▇▇▅▇▇▇ ## mid 1.4072916666666666 0.49 1.000 2.00 ▇▁▁▁▁▁▁▁▁▅ 5.2.3 Models m6.9 &lt;- quap( alist( happiness ~ dnorm(mu, sigma), mu &lt;- a[mid] + bA * A, a[mid] ~ dnorm(0, 1), bA ~ dnorm(0, 2), sigma ~ dexp(1) ), data = d2 ) precis(m6.9, depth = 2) ## mean sd 5.5% 94.5% ## a[1] -0.24 0.063 -0.34 -0.13 ## a[2] 1.26 0.085 1.12 1.39 ## bA -0.75 0.113 -0.93 -0.57 ## sigma 0.99 0.023 0.95 1.03 m6.10 &lt;- quap( alist( happiness ~ dnorm(mu, sigma), mu &lt;- a + bA * A, a ~ dnorm(0, 1), bA ~ dnorm(0, 2), sigma ~ dexp(1) ), data = d2 ) precis(m6.10, depth = 2) ## mean sd 5.5% 94.5% ## a 0.00000016 0.077 -0.12 0.12 ## bA -0.00000027 0.132 -0.21 0.21 ## sigma 1.21318761 0.028 1.17 1.26 5.2.4 Interpretation Compare these two models using WAIC (or LOO, they will produce identical results). Which model is expected to make better predictions? Which model provides the correct causal inference about the influence of age on happiness? Can you explain why the answers to these two questions disagree? compare(m6.9, m6.10) ## WAIC SE dWAIC dSE pWAIC weight ## m6.9 2714 38 0 NA 3.7 1 ## m6.10 3102 28 388 35 2.3 0 Model m6.9 includes marriage while m6.10 does not. The causal influence of age on happiness is confounded by marriage because marriage is a collider between age and happiness. Conditioning on marriage opens the path between age and happiness, making age and happiness independent. Therefore, despite the WAIC for m6.9 being lower, it does not tell us anything about causation between the variables. 5.3 Question 3 Reconsider the urban fox analysis from last week’s homework. Use WAIC or LOO based model comparison on five different models, each using weight as the outcome, and containing these sets of predictor variables: avgfood + groupsize + area avgfood + groupsize groupsize + area avgfood area 5.3.1 Data library(rethinking) data(foxes) 5.3.2 Models foxes$scale_area &lt;- scale(foxes$area) foxes$scale_weight &lt;- scale(foxes$weight) foxes$scale_avgfood &lt;- scale(foxes$avgfood) foxes$scale_groupsize &lt;- scale(foxes$groupsize) m1 &lt;- quap( alist( scale_weight ~ dnorm(mu, sigma), mu &lt;- a + bFood * scale_avgfood + bGroup * scale_groupsize + bArea * scale_area, a ~ dnorm(0, 0.2), bFood ~ dnorm(0, 0.5), bGroup ~ dnorm(0, 0.5), bArea ~ dnorm(0, 0.5), sigma ~ dunif(0, 50) ), data = foxes ) m2 &lt;- quap( alist( scale_weight ~ dnorm(mu, sigma), mu &lt;- a + bFood * scale_avgfood + bGroup * scale_groupsize, a ~ dnorm(0, 0.2), bFood ~ dnorm(0, 0.5), bGroup ~ dnorm(0, 0.5), sigma ~ dunif(0, 50) ), data = foxes ) m3 &lt;- quap( alist( scale_weight ~ dnorm(mu, sigma), mu &lt;- a + bGroup * scale_groupsize + bArea * scale_area, a ~ dnorm(0, 0.2), bArea ~ dnorm(0, 0.5), bGroup ~ dnorm(0, 0.5), sigma ~ dunif(0, 50) ), data = foxes ) m4 &lt;- quap( alist( scale_weight ~ dnorm(mu, sigma), mu &lt;- a + bFood * scale_avgfood, a ~ dnorm(0, 0.2), bFood ~ dnorm(0, 0.5), sigma ~ dunif(0, 50) ), data = foxes ) m5 &lt;- quap( alist( scale_weight ~ dnorm(mu, sigma), mu &lt;- a + bArea * scale_area, a ~ dnorm(0, 0.2), bArea ~ dnorm(0, 0.5), sigma ~ dunif(0, 50) ), data = foxes ) 5.3.3 DAG dag &lt;- dagify( weight ~ groupsize + avgfood, groupsize ~ avgfood, avgfood ~ area, exposure = &#39;area&#39;, outcome = &#39;weight&#39; ) dag_plot(dag) 5.3.4 Interpretation Can you explain the relative differences in WAIC scores, using the fox DAG from last week’s homework? Be sure to pay attention to the standard error of the score differences (dSE). weight ~ avgfood + groupsize + area weight ~ avgfood + groupsize weight ~ groupsize + area weight ~ avgfood weight ~ area compare_models &lt;- compare(m1, m2, m3, m4, m5) compare_models ## WAIC SE dWAIC dSE pWAIC weight ## m1 323 16 0.00 NA 4.6 0.4568 ## m2 324 16 0.97 3.6 3.7 0.2811 ## m3 324 16 1.15 2.9 3.8 0.2575 ## m4 333 14 10.56 7.1 2.4 0.0023 ## m5 334 14 10.66 7.2 2.6 0.0022 compare_models@dSE ## m1 m2 m3 m4 m5 ## m1 NA 3.6 2.9 7.13 7.19 ## m2 3.6 NA 5.8 6.55 6.79 ## m3 2.9 5.8 NA 6.54 6.59 ## m4 7.1 6.5 6.5 NA 0.84 ## m5 7.2 6.8 6.6 0.84 NA # Filled points: in-sample deviance # Open points: WAIC # Dark lines: standard error of WAIC # Light lines with triangles: standard error of difference in WAIC between each model and top model plot(compare_models) coeftab(m1, m2, m3, m4, m5) ## m1 m2 m3 m4 m5 ## a 0 0 0 0 0 ## bFood 0.30 0.48 NA -0.02 NA ## bGroup -0.64 -0.57 -0.48 NA NA ## bArea 0.28 NA 0.41 NA 0.02 ## sigma 0.93 0.95 0.95 1.00 1.00 ## nobs 116 116 116 116 116 Weight is the outcome in all of the models. Looking at the DAG, we see a potential back door into avgfood and group size, but no colliders. Avgfood is a path between area and weight, as is groupsize between avgfood and weight. The paths for each variable that does not have confounds shown in the DAG: Model 2: Weight ~ groupsize + avgfood (to determine causal effect of groupsize on weight, including avgfood to open the collider) Model 4: Weight ~ avgfood (to determine causal effect of avgfood, without groupsize confusing the relationship since it’s a pipe) Model 5: Weight ~ area (with avgfood and groupsize excluded) Model 1 includes the most parameters and, as expected, has the highest model fit. The dSE column returned by the compare function indicates the standard error of the difference between models, with the @dSE slot showing this for all combinations of models. Models 4 and 5 barely differ, as there is likely a strong influence of area on average food. Including both area and avgfood is like conditioning on the intermediate treatment effect. Models 4 and 5 are most different from models 1, 2, 3. Models 1, 2, and 3 all have groupsize and the WAIC and coeftab, as well as the DAG, indicate the models have the same inference. "],["homework-week-5.html", "6 Homework: Week 5 6.1 Question 1 6.2 Question 2 6.3 Question 3", " 6 Homework: Week 5 2021-09-03 [updated: 2021-09-08] 6.0.1 Setup # Packages library(ggdag) library(dagitty) library(data.table) library(ggplot2) library(tidybayes) # Functions dag_plot &lt;- function(dag) { stat &lt;- node_status(dag, FALSE) stat$data$status[is.na(stat$data$status)] &lt;- &#39;intermediate&#39; ggplot(stat, aes(x = x, y = y, xend = xend, yend = yend)) + geom_dag_point(aes(color = status), alpha = 0.5, size = 15) + geom_dag_edges() + labs(color = &#39;&#39;) + geom_dag_text(color = &#39;black&#39;) + scale_color_manual(values = list(&#39;exposure&#39; = &#39;#35608DFF&#39;, &#39;outcome&#39; = &#39;#22A884FF&#39;, &#39;intermediate&#39; = &#39;grey50&#39;)) + theme_void() } cmd_draws &lt;- function(model) { as_draws_df(model$draws()) } 6.1 Question 1 Consider the data(Wines2012) data table. These data are expert ratings of 20 different French and American wines by 9 different French and American judges. 6.1.1 Data Your goal is to model score, the subjective rating assigned by each judge to each wine. I recommend standardizing it. In this first problem, consider only variation among judges and wines. Construct index variables of judge and wine and then use these index variables to construct a linear regression model. library(rethinking) library(cmdstanr) ## This is cmdstanr version 0.4.0.9000 ## - Online documentation and vignettes at mc-stan.org/cmdstanr ## - CmdStan path set to: /home/alecr/.cmdstan/cmdstan-2.27.0 ## - Use set_cmdstan_path() to change the path library(data.table) library(posterior) ## This is posterior version 1.0.1 ## ## Attaching package: &#39;posterior&#39; ## The following objects are masked from &#39;package:rstan&#39;: ## ## ess_bulk, ess_tail ## The following objects are masked from &#39;package:stats&#39;: ## ## mad, sd, var library(bayesplot) ## This is bayesplot version 1.8.1 ## - Online documentation and vignettes at mc-stan.org/bayesplot ## - bayesplot theme set to bayesplot::theme_default() ## * Does _not_ affect other ggplot2 plots ## * See ?bayesplot_theme_set for details on theme setting ## ## Attaching package: &#39;bayesplot&#39; ## The following object is masked from &#39;package:posterior&#39;: ## ## rhat data(&quot;Wines2012&quot;) DT &lt;- data.table(Wines2012) DT[, scale_score := scale(score)] DT[, index_judge := .GRP, judge] DT[, index_wine := .GRP, wine] n_index_judge &lt;- DT[, uniqueN(index_judge)] n_index_wine &lt;- DT[, uniqueN(index_wine)] n_rows &lt;- DT[, .N] 6.1.2 Prior predictive simulation register_knitr_engine(override = FALSE) data { int&lt;lower=0&gt; N; int&lt;lower=0&gt; N_judges; int&lt;lower=0&gt; N_wines; } parameters{ real alpha; vector[N_judges] beta_judge; vector[N_wines] beta_wine; real&lt;lower=0&gt; sigma; } model{ sigma ~ exponential(1); beta_wine ~ normal(0, 0.5); beta_judge~normal(0, 0.5); alpha~normal(0, 0.2); } # q1_stan &lt;- &#39;q1_prior.stan&#39; # writeLines(readLines(q1_stan)) # q1_prior &lt;- cmdstan_model(q1_stan) q1_prior_sample &lt;- q1_prior$sample( data = list(N = n_rows, N_judges = n_index_judge, N_wines = n_index_wine) ) ## Running MCMC with 4 sequential chains... ## ## Chain 1 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 1 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 1 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 1 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 1 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 1 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 1 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 1 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 1 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 1 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 1 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 1 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 1 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 1 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 1 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 1 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 1 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 1 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 1 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 1 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 1 finished in 0.1 seconds. ## Chain 2 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 2 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 2 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 2 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 2 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 2 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 2 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 2 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 2 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 2 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 2 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 2 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 2 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 2 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 2 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 2 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 2 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 2 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 2 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 2 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 2 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 2 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 2 finished in 0.1 seconds. ## Chain 3 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 3 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 3 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 3 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 3 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 3 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 3 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 3 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 3 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 3 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 3 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 3 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 3 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 3 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 3 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 3 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 3 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 3 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 3 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 3 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 3 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 3 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 3 finished in 0.1 seconds. ## Chain 4 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 4 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 4 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 4 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 4 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 4 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 4 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 4 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 4 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 4 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 4 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 4 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 4 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 4 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 4 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 4 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 4 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 4 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 4 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 4 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 4 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 4 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 4 finished in 0.1 seconds. ## ## All 4 chains finished successfully. ## Mean chain execution time: 0.1 seconds. ## Total execution time: 0.6 seconds. q1_prior_draws &lt;- cmd_draws(q1_prior_sample) mcmc_areas(q1_prior_draws, regex_pars = &#39;judge&#39;) mcmc_areas(q1_prior_draws, regex_pars = &#39;wine&#39;) Justify your priors. You should end up with 9 judge parameters and 20 wine parameters. Given the parameters are scaled, the prior predictive plots show scaled wine scores mostly between -2 and 2. Since we do not have any prior knowledge about how this relationship (positive/negative slopes), we are satisfied with this relatively conservative prior. 6.1.3 Model Use ulam instead of quap to build this model, and be sure to check the chains for convergence. If you’d rather build the model directly in Stan or PyMC3, go ahead. I just want you to use Hamiltonian Monte Carlo instead of quadratic approximation. data { int&lt;lower=0&gt; N; int&lt;lower=0&gt; N_judges; int&lt;lower=0&gt; N_wines; int index_judge[N]; int index_wine[N]; vector[N] scale_score; } parameters{ real alpha; vector[N_judges] beta_judge; vector[N_wines] beta_wine; real&lt;lower=0&gt; sigma; } model{ alpha ~ normal(0, 0.2); beta_wine ~ normal(0, 0.5); beta_judge ~ normal(0, 0.5); sigma ~ exponential(1); vector[N] mu; mu = beta_wine[index_wine] + beta_judge[index_judge]; scale_score ~ normal(mu, sigma); } # q1_stan &lt;- &#39;q1.stan&#39; # writeLines(readLines(q1_stan)) # q1_model &lt;- cmdstan_model(q1_stan) q1_sample &lt;- q1_model$sample( data = list(N = n_rows, N_judges = n_index_judge, N_wines = n_index_wine, scale_score = DT[, as.numeric(scale_score)], index_judge = DT[, index_judge], index_wine = DT[, index_wine] ) ) ## Running MCMC with 4 sequential chains... ## ## Chain 1 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 1 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 1 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 1 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 1 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 1 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 1 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 1 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 1 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 1 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 1 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 1 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 1 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 1 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 1 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 1 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 1 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 1 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 1 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 1 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 1 finished in 0.1 seconds. ## Chain 2 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 2 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 2 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 2 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 2 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 2 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 2 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 2 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 2 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 2 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 2 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 2 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 2 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 2 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 2 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 2 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 2 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 2 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 2 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 2 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 2 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 2 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 2 finished in 0.1 seconds. ## Chain 3 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 3 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 3 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 3 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 3 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 3 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 3 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 3 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 3 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 3 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 3 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 3 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 3 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 3 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 3 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 3 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 3 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 3 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 3 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 3 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 3 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 3 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 3 finished in 0.1 seconds. ## Chain 4 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 4 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 4 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 4 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 4 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 4 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 4 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 4 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 4 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 4 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 4 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 4 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 4 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 4 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 4 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 4 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 4 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 4 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 4 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 4 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 4 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 4 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 4 finished in 0.1 seconds. ## ## All 4 chains finished successfully. ## Mean chain execution time: 0.1 seconds. ## Total execution time: 0.9 seconds. q1_draws &lt;- cmd_draws(q1_sample) setDT(q1_draws) How do you interpret the variation among individual judges and individual wines? Do you notice any patterns, just by plotting the differences? Which judges gave the highest/lowest ratings? Which wines were rated worst/ best on average? # Judges precis(q1_draws, depth = 2)[3:11,] ## mean sd 5.5% 94.5% histogram ## beta_judge[1] -0.54 0.19 -0.850 -0.230 ▁▁▁▁▂▃▇▇▅▅▂▁▁▁▁ ## beta_judge[2] -0.35 0.19 -0.662 -0.046 ▁▁▂▅▇▃▁▁▁ ## beta_judge[3] 0.79 0.20 0.470 1.113 ▁▁▁▂▃▅▇▇▅▃▂▁▁▁ ## beta_judge[4] 0.13 0.19 -0.176 0.442 ▁▁▁▁▂▅▇▇▇▃▂▁▁▁ ## beta_judge[5] -0.66 0.19 -0.966 -0.352 ▁▁▃▇▅▂▁▁ ## beta_judge[6] 0.47 0.20 0.169 0.785 ▁▁▁▂▃▇▇▇▅▃▁▁▁▁ ## beta_judge[7] -0.28 0.20 -0.598 0.040 ▁▁▁▂▃▅▇▇▇▃▂▁▁▁▁ ## beta_judge[8] 0.20 0.19 -0.108 0.517 ▁▁▂▇▇▂▁▁ ## beta_judge[9] 0.21 0.19 -0.087 0.522 ▁▁▂▇▇▂▁▁ melt(q1_draws, measure.vars = patterns(&#39;beta_judge&#39;))[, .(mean_score = mean(value)), variable][order(-mean_score)] ## variable mean_score ## &lt;fctr&gt; &lt;num&gt; ## 1: beta_judge[3] 0.79 ## 2: beta_judge[6] 0.47 ## 3: beta_judge[9] 0.21 ## 4: beta_judge[8] 0.20 ## 5: beta_judge[4] 0.13 ## 6: beta_judge[7] -0.28 ## 7: beta_judge[2] -0.35 ## 8: beta_judge[1] -0.54 ## 9: beta_judge[5] -0.66 mcmc_areas(q1_draws, regex_pars = &#39;judge&#39;) # Wines precis(q1_draws, depth = 2)[12:31,] ## mean sd 5.5% 94.5% histogram ## beta_wine[1] 0.1169 0.25 -0.289 0.51 ▁▁▂▅▇▅▂▁▁ ## beta_wine[2] 0.2350 0.27 -0.196 0.65 ▁▁▁▁▃▇▇▅▂▁▁▁ ## beta_wine[3] -0.1017 0.26 -0.513 0.30 ▁▁▁▂▅▇▅▂▁▁▁ ## beta_wine[4] 0.2467 0.27 -0.181 0.67 ▁▁▁▃▇▇▅▂▁▁ ## beta_wine[5] 0.0767 0.26 -0.328 0.48 ▁▁▁▂▇▇▅▂▁▁ ## beta_wine[6] -0.0092 0.26 -0.418 0.40 ▁▁▁▃▇▇▃▁▁▁ ## beta_wine[7] -0.0859 0.26 -0.510 0.34 ▁▁▁▂▅▇▅▂▁▁ ## beta_wine[8] -0.1821 0.25 -0.584 0.21 ▁▁▁▃▇▇▅▁▁▁ ## beta_wine[9] -0.1224 0.25 -0.532 0.28 ▁▁▂▅▇▅▂▁▁▁ ## beta_wine[10] -0.1299 0.26 -0.539 0.28 ▁▁▁▂▇▇▅▂▁▁ ## beta_wine[11] 0.0924 0.26 -0.332 0.51 ▁▁▂▅▇▅▂▁▁▁ ## beta_wine[12] 0.4705 0.25 0.055 0.87 ▁▁▂▅▇▅▂▁▁ ## beta_wine[13] -0.3115 0.26 -0.723 0.11 ▁▁▂▅▇▅▂▁▁▁ ## beta_wine[14] 0.2321 0.26 -0.177 0.64 ▁▁▃▇▇▃▂▁▁ ## beta_wine[15] 0.0986 0.26 -0.308 0.51 ▁▁▂▅▇▅▂▁▁▁ ## beta_wine[16] -0.0233 0.26 -0.423 0.39 ▁▁▁▅▇▇▃▁▁▁▁ ## beta_wine[17] 0.0075 0.26 -0.399 0.42 ▁▁▁▃▇▇▃▁▁▁▁ ## beta_wine[18] -0.1644 0.26 -0.573 0.24 ▁▁▁▃▇▇▃▁▁▁ ## beta_wine[19] -0.7197 0.25 -1.122 -0.32 ▁▁▂▇▇▅▂▁▁ ## beta_wine[20] 0.3240 0.26 -0.098 0.72 ▁▁▂▅▇▇▂▁▁▁ melt(q1_draws, measure.vars = patterns(&#39;beta_wine&#39;))[, .(mean_score = mean(value)), variable][order(-mean_score)] ## variable mean_score ## &lt;fctr&gt; &lt;num&gt; ## 1: beta_wine[12] 0.4705 ## 2: beta_wine[20] 0.3240 ## 3: beta_wine[4] 0.2467 ## 4: beta_wine[2] 0.2350 ## 5: beta_wine[14] 0.2321 ## 6: beta_wine[1] 0.1169 ## 7: beta_wine[15] 0.0986 ## 8: beta_wine[11] 0.0924 ## 9: beta_wine[5] 0.0767 ## 10: beta_wine[17] 0.0075 ## 11: beta_wine[6] -0.0092 ## 12: beta_wine[16] -0.0233 ## 13: beta_wine[7] -0.0859 ## 14: beta_wine[3] -0.1017 ## 15: beta_wine[9] -0.1224 ## 16: beta_wine[10] -0.1299 ## 17: beta_wine[18] -0.1644 ## 18: beta_wine[8] -0.1821 ## 19: beta_wine[13] -0.3115 ## 20: beta_wine[19] -0.7197 ## variable mean_score mcmc_areas(q1_draws, regex_pars = &#39;wine&#39;) Accounting for judges, most wines are scored with similar distributions. Wine 19 however was particularly poorly scored. Judges, however, have much more variable scoring with three individuals (judges 1, 2, 5) entirely or almost entirely scoring lower than other judges. The worst scoring judge was judge 5. 6.2 Question 2 Now consider three features of the wines and judges: (1) flight: Whether the wine is red or white. (2) wine.amer: Indicator variable for American wines. (3) judge.amer: Indicator variable for American judges. Use indicator or index variables to model the influence of these features on the scores. Omit the individual judge and wine index variables from Problem 1. Do not include interaction effects yet. Again use ulam, justify your priors, and be sure to check the chains. 6.2.1 Data DT[, scale_score := scale(score)] DT[, index_flight := .GRP, flight] DT[, index_wine_american := .GRP, wine.amer] DT[, index_judge_american := .GRP, judge.amer] n_index_flight &lt;- DT[, uniqueN(flight)] n_index_wine_american &lt;- DT[, uniqueN(index_wine_american)] n_index_judge_american &lt;- DT[, uniqueN(index_judge_american)] n_rows &lt;- DT[, .N] q2_data &lt;- c( as.list(DT[, .(scale_score = as.numeric(scale_score), index_flight, index_wine_american, index_judge_american)]), N_flights = n_index_flight, N_wine_american = n_index_wine_american, N_judge_american = n_index_judge_american, N = n_rows ) 6.2.2 Priors data { int&lt;lower=0&gt; N; int&lt;lower=0&gt; N_flights; int&lt;lower=0&gt; N_wine_american; int&lt;lower=0&gt; N_judge_american; } parameters{ real alpha; vector[N_flights] beta_flights; vector[N_wine_american] beta_wine_american; vector[N_judge_american] beta_judge_american; real&lt;lower=0&gt; sigma; } model{ alpha ~ normal(0, 0.2); beta_flights ~ normal(0, 0.5); beta_wine_american ~ normal(0, 0.5); beta_judge_american ~ normal(0, 0.5); sigma ~ exponential(1); } # q2_stan &lt;- &#39;q2_prior.stan&#39; # writeLines(readLines(q2_stan)) # q2_prior &lt;- cmdstan_model(q2_stan) q2_prior_sample &lt;- q2_prior$sample(data = q2_data[c(&#39;N_flights&#39;, &#39;N_wine_american&#39;, &#39;N_judge_american&#39;, &#39;N&#39;)]) ## Running MCMC with 4 sequential chains... ## ## Chain 1 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 1 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 1 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 1 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 1 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 1 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 1 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 1 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 1 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 1 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 1 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 1 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 1 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 1 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 1 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 1 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 1 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 1 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 1 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 1 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 1 finished in 0.0 seconds. ## Chain 2 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 2 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 2 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 2 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 2 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 2 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 2 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 2 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 2 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 2 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 2 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 2 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 2 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 2 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 2 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 2 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 2 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 2 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 2 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 2 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 2 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 2 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 2 finished in 0.0 seconds. ## Chain 3 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 3 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 3 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 3 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 3 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 3 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 3 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 3 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 3 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 3 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 3 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 3 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 3 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 3 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 3 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 3 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 3 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 3 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 3 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 3 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 3 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 3 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 3 finished in 0.0 seconds. ## Chain 4 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 4 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 4 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 4 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 4 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 4 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 4 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 4 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 4 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 4 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 4 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 4 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 4 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 4 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 4 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 4 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 4 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 4 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 4 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 4 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 4 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 4 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 4 finished in 0.0 seconds. ## ## All 4 chains finished successfully. ## Mean chain execution time: 0.0 seconds. ## Total execution time: 0.5 seconds. q2_prior_draws &lt;- cmd_draws(q2_prior_sample) mcmc_areas(q2_prior_draws, regex_pars = &#39;flights&#39;) mcmc_areas(q2_prior_draws, regex_pars = &#39;judge&#39;) mcmc_areas(q2_prior_draws, regex_pars = &#39;wine&#39;) 6.2.3 Model data { int&lt;lower=0&gt; N; int&lt;lower=0&gt; N_flights; int&lt;lower=0&gt; N_wine_american; int&lt;lower=0&gt; N_judge_american; int index_flight[N]; int index_wine_american[N]; int index_judge_american[N]; vector[N] scale_score; } parameters{ real alpha; vector[N_flights] beta_flights; vector[N_wine_american] beta_wine_american; vector[N_judge_american] beta_judge_american; real&lt;lower=0&gt; sigma; } model{ alpha ~ normal(0, 0.2); beta_flights ~ normal(0, 0.5); beta_wine_american ~ normal(0, 0.5); beta_judge_american ~ normal(0, 0.5); sigma ~ exponential(1); vector[N] mu; mu = beta_flights[index_flight] + beta_wine_american[index_wine_american] + beta_judge_american[index_judge_american]; scale_score ~ normal(mu, sigma); } # q2_stan &lt;- &#39;q2.stan&#39; # writeLines(readLines(q2_stan)) # q2_model &lt;- cmdstan_model(q2_stan) q2_sample &lt;- q2_model$sample(data = q2_data) ## Running MCMC with 4 sequential chains... ## ## Chain 1 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 1 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 1 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 1 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 1 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b13b4ac83.stan&#39;, line 29, column 2 to column 34) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 1 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 1 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 1 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 1 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 1 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 1 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 1 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 1 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 1 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 1 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 1 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 1 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 1 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 1 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 1 finished in 0.4 seconds. ## Chain 2 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 2 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 2 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 2 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 2 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 2 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b13b4ac83.stan&#39;, line 29, column 2 to column 34) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 2 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 2 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 2 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 2 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 2 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 2 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 2 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 2 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 2 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 2 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 2 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 2 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 2 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 2 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 2 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 2 finished in 0.3 seconds. ## Chain 3 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 3 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 3 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 3 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 3 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 3 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 3 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 3 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 3 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 3 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 3 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 3 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 3 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 3 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 3 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 3 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 3 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 3 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 3 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 3 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 3 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 3 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 3 finished in 0.4 seconds. ## Chain 4 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 4 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 4 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 4 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 4 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 4 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 4 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 4 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 4 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 4 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 4 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 4 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 4 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 4 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 4 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 4 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 4 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 4 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 4 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 4 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 4 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 4 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 4 finished in 0.3 seconds. ## ## All 4 chains finished successfully. ## Mean chain execution time: 0.3 seconds. ## Total execution time: 1.7 seconds. q2_draws &lt;- cmd_draws(q2_sample) q2_sample$summary() ## # A tibble: 9 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 lp__ -9.24e+1 -9.21e+1 1.98 1.86 -96.1 -89.8 1.00 1571. ## 2 alpha -4.17e-4 6.40e-4 0.195 0.189 -0.321 0.328 1.00 3239. ## 3 beta_flights[… 3.00e-3 -1.70e-3 0.294 0.297 -0.479 0.488 1.00 1648. ## 4 beta_flights[… 2.13e-3 -2.85e-4 0.295 0.296 -0.480 0.488 1.00 1653. ## 5 beta_wine_ame… -9.75e-2 -9.93e-2 0.299 0.297 -0.586 0.400 1.00 1965. ## 6 beta_wine_ame… 8.43e-2 7.48e-2 0.304 0.299 -0.416 0.596 1.00 2007. ## 7 beta_judge_am… -1.12e-1 -1.06e-1 0.300 0.302 -0.610 0.375 1.00 1683. ## 8 beta_judge_am… 1.28e-1 1.31e-1 0.296 0.300 -0.363 0.608 1.00 1615. ## 9 sigma 1.00e+0 9.98e-1 0.0530 0.0520 0.918 1.09 1.00 3488. ## # … with 1 more variable: ess_tail &lt;dbl&gt; mcmc_trace(q2_draws) # Recall: DT[, .N, .(flight, index_flight)] ## flight index_flight N ## &lt;fctr&gt; &lt;int&gt; &lt;int&gt; ## 1: white 1 90 ## 2: red 2 90 DT[, .N, .(judge.amer, index_judge_american)] ## judge.amer index_judge_american N ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1: 0 1 80 ## 2: 1 2 100 DT[, .N, .(wine.amer, index_wine_american)] ## wine.amer index_wine_american N ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1: 1 1 108 ## 2: 0 2 72 labs &lt;- c( &#39;beta_flights[1]&#39; = &#39;White Wine&#39;, &#39;beta_flights[2]&#39; = &#39;Red Wine&#39;, &#39;beta_wine_american[1]&#39; = &#39;French Wine&#39;, &#39;beta_wine_american[2]&#39; = &#39;American Wine&#39;, &#39;beta_judge_american[1]&#39; = &#39;American Judge&#39;, &#39;beta_judge_american[2]&#39; = &#39;French Judge&#39; ) mcmc_areas(q2_draws, regex_pars = &#39;flight&#39;) + scale_y_discrete(labels = labs) ## Scale for &#39;y&#39; is already present. Adding another scale for &#39;y&#39;, which will ## replace the existing scale. mcmc_areas(q2_draws, regex_pars = &#39;judge&#39;) + scale_y_discrete(labels = labs) ## Scale for &#39;y&#39; is already present. Adding another scale for &#39;y&#39;, which will ## replace the existing scale. mcmc_areas(q2_draws, regex_pars = &#39;wine&#39;) + scale_y_discrete(labels = labs) ## Scale for &#39;y&#39; is already present. Adding another scale for &#39;y&#39;, which will ## replace the existing scale. 6.3 Question 3 Now consider two-way interactions among the three features. You should end up with three different interaction terms in your model. These will be easier to build, if you use indicator variables. Again use ulam, justify your priors, and be sure to check the chains. Explain what each interaction means. Be sure to interpret the model’s predictions on the outcome scale (mu, the expected score), not on the scale of individual parameters. You can use link to help with this, or just use your knowledge of the linear model instead. What do you conclude about the features and the scores? Can you relate the results of your model(s) to the individual judge and wine inferences from Problem 1? 6.3.1 Data DT[, index_interactions := .GRP, .(judge.amer, wine.amer, flight)] n_index_interactions &lt;- DT[, uniqueN(index_interactions)] q3_data &lt;- c( as.list(DT[, .(scale_score = as.numeric(scale_score), index_interactions)]), N_interactions = n_index_interactions, N = n_rows ) 6.3.2 Model data { int&lt;lower=0&gt; N; int&lt;lower=0&gt; N_interactions; int index_interactions[N]; vector[N] scale_score; } parameters{ real alpha; vector[N_interactions] beta_interactions; real&lt;lower=0&gt; sigma; } model{ alpha ~ normal(0, 0.2); beta_interactions ~ normal(0, 0.25); sigma ~ exponential(1); vector[N] mu; mu = alpha + beta_interactions[index_interactions]; scale_score ~ normal(mu, sigma); } # q3_stan &lt;- &#39;q3.stan&#39; # writeLines(readLines(q3_stan)) # q3_model &lt;- cmdstan_model(q3_stan) q3_sample &lt;- q3_model$sample(data = q3_data) ## Running MCMC with 4 sequential chains... ## ## Chain 1 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 1 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 1 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 1 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 1 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 1 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 1 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 1 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 1 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 1 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 1 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 1 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 1 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 1 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 1 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 1 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 1 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 1 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 1 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 1 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b3fbbe88.stan&#39;, line 22, column 2 to column 34) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 finished in 0.1 seconds. ## Chain 2 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 2 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 2 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 2 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 2 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 2 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 2 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 2 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 2 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 2 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 2 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 2 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 2 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 2 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 2 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 2 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 2 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 2 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 2 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 2 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 2 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 2 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b3fbbe88.stan&#39;, line 22, column 2 to column 34) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 finished in 0.1 seconds. ## Chain 3 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 3 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 3 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 3 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 3 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 3 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 3 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 3 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 3 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 3 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 3 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 3 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 3 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 3 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 3 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 3 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 3 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 3 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 3 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 3 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 3 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 3 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 3 finished in 0.1 seconds. ## Chain 4 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 4 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 4 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 4 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 4 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 4 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 4 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 4 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 4 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 4 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 4 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 4 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 4 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 4 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 4 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 4 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 4 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 4 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 4 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 4 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 4 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 4 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 4 finished in 0.1 seconds. ## ## All 4 chains finished successfully. ## Mean chain execution time: 0.1 seconds. ## Total execution time: 0.5 seconds. q3_draws &lt;- cmd_draws(q3_sample) q3_sample$summary() ## # A tibble: 11 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 lp__ -9.25e+1 -9.21e+1 2.23 2.19 -96.6 -89.5 1.00 1685. ## 2 alpha 3.04e-3 1.47e-3 0.102 0.103 -0.163 0.171 1.00 2967. ## 3 beta_interac… 2.20e-2 2.30e-2 0.168 0.169 -0.255 0.298 1.00 4727. ## 4 beta_interac… -1.94e-1 -1.93e-1 0.183 0.186 -0.489 0.119 1.00 5951. ## 5 beta_interac… 2.47e-2 2.47e-2 0.161 0.164 -0.239 0.291 1.00 5071. ## 6 beta_interac… 1.11e-1 1.12e-1 0.173 0.173 -0.172 0.399 1.00 5830. ## 7 beta_interac… 1.24e-1 1.25e-1 0.186 0.186 -0.187 0.425 1.00 6681. ## 8 beta_interac… -2.54e-1 -2.55e-1 0.165 0.165 -0.519 0.0199 1.00 4979. ## 9 beta_interac… 1.77e-1 1.75e-1 0.180 0.177 -0.122 0.479 1.00 6038. ## 10 beta_interac… -1.36e-2 -1.13e-2 0.164 0.167 -0.283 0.250 1.00 5091. ## 11 sigma 9.92e-1 9.89e-1 0.0522 0.0507 0.909 1.08 1.00 7469. ## # … with 1 more variable: ess_tail &lt;dbl&gt; mcmc_trace(q3_draws) DT[, judge_char := ifelse(judge.amer == 0, &#39;French Judge&#39;, &#39;American Judge&#39;)] DT[, wine_char := ifelse(wine.amer == 0, &#39;French Wine&#39;, &#39;American Wine&#39;)] labs &lt;- DT[, .(.GRP, paste(.BY, collapse = &#39;, &#39;)), by = .(wine_char, judge_char, as.character(flight))][, .(GRP, V2)] labs &lt;- setNames(labs$V2, paste0(&#39;beta_interactions[&#39;, labs$GRP, &#39;]&#39;)) mcmc_areas(q3_draws, regex_pars = &#39;interaction&#39;) + scale_y_discrete(labels = labs) ## Scale for &#39;y&#39; is already present. Adding another scale for &#39;y&#39;, which will ## replace the existing scale. "],["homework-week-6.html", "7 Homework: Week 6 7.1 Question 1", " 7 Homework: Week 6 2021-09-06 [updated: 2021-09-08] 7.0.1 Setup # Packages library(ggdag) library(dagitty) library(data.table) library(ggplot2) library(rethinking) library(cmdstanr) library(posterior) library(bayesplot) library(boot) ## ## Attaching package: &#39;boot&#39; ## The following object is masked from &#39;package:rethinking&#39;: ## ## logit # Functions dag_plot &lt;- function(dag) { stat &lt;- node_status(dag, FALSE) stat$data$status[is.na(stat$data$status)] &lt;- &#39;intermediate&#39; ggplot(stat, aes(x = x, y = y, xend = xend, yend = yend)) + geom_dag_point(aes(color = status), alpha = 0.5, size = 15) + geom_dag_edges() + labs(color = &#39;&#39;) + geom_dag_text(color = &#39;black&#39;) + scale_color_manual(values = list(&#39;exposure&#39; = &#39;#35608DFF&#39;, &#39;outcome&#39; = &#39;#22A884FF&#39;, &#39;intermediate&#39; = &#39;grey50&#39;)) + theme_void() } cmd_draws &lt;- function(model) { as_draws_df(model$draws()) } 7.1 Question 1 The data in data(NWOGrants) are outcomes for scientific funding applications for the Netherlands Organization for Scientific Research (NWO) from 2010–2012 (see van der Lee and Ellemers doi:10.1073/pnas.1510159112). These data have a very similar structure to the UCBAdmit data discussed in Chapter 11. I want you to consider a similar question: What are the total and indirect causal effects of gender on grant awards? Consider a mediation path (a pipe) through dis- cipline. Draw the corresponding DAG and then use one or more binomial GLMs to answer the question. 7.1.1 Data data(NWOGrants) setDT(NWOGrants) precis(NWOGrants) ## mean sd 5.5% 94.5% histogram ## discipline NaN NA NA NA ## gender NaN NA NA NA ## applications 157 120 37.0 410 ▅▇▅▅▃▂▁▁▃ ## awards 26 16 8.5 48 ▂▅▅▇▂▇▅▂▁▅▁▁▂ summary(NWOGrants) ## discipline gender applications awards ## Chemical sciences :2 f:9 Min. : 9 Min. : 2 ## Earth/life sciences:2 m:9 1st Qu.: 70 1st Qu.:14 ## Humanities :2 Median :130 Median :24 ## Interdisciplinary :2 Mean :157 Mean :26 ## Medical sciences :2 3rd Qu.:220 3rd Qu.:33 ## Physical sciences :2 Max. :425 Max. :65 ## (Other) :6 Discipline: factor with 9 levels Gender: factor with 2 levels in this data (…) Applications: count Awards: count NWOGrants[, index_gender := .GRP, gender] NWOGrants[, index_discipline := .GRP, discipline] q1_data &lt;- c( as.list(NWOGrants[, .(awards, applications, index_gender, index_discipline)]), N = NWOGrants[, .N], N_gender = NWOGrants[, uniqueN(index_gender)], N_discipline = NWOGrants[, uniqueN(index_discipline)] ) 7.1.2 DAG dag &lt;- dagify( awards ~ index_gender + index_discipline, index_discipline ~ index_gender, exposure = &#39;index_gender&#39;, outcome = &#39;awards&#39; ) dag_plot(dag) 7.1.3 Priors register_knitr_engine(override = FALSE) data { int&lt;lower=0&gt; N; int&lt;lower=0&gt; N_gender; int&lt;lower=0&gt; N_discipline; } parameters{ real alpha; vector[N_gender] beta_gender; vector[N_discipline] beta_discipline; real&lt;lower=0&gt; sigma; real&lt;lower=0,upper=1&gt; theta; } model{ alpha ~ normal(0, 0.2); beta_gender ~ normal(0, 0.25); beta_discipline ~ normal(0, 0.25); sigma ~ exponential(1); theta ~ beta(1, 1); } # q1_stan &lt;- &#39;q1_prior.stan&#39; # writeLines(readLines(q1_stan)) # q1_prior &lt;- cmdstan_model(q1_stan) q1_prior_sample &lt;- q1_prior$sample(data = q1_data[c(&#39;N&#39;, &#39;N_gender&#39;, &#39;N_discipline&#39;)]) ## Running MCMC with 4 sequential chains... ## ## Chain 1 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 1 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 1 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 1 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 1 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 1 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 1 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 1 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 1 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 1 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 1 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 1 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 1 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 1 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 1 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 1 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 1 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 1 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 1 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 1 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 1 finished in 0.0 seconds. ## Chain 2 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 2 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 2 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 2 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 2 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 2 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 2 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 2 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 2 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 2 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 2 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 2 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 2 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 2 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 2 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 2 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 2 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 2 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 2 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 2 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 2 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 2 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 2 finished in 0.0 seconds. ## Chain 3 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 3 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 3 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 3 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 3 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 3 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 3 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 3 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 3 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 3 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 3 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 3 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 3 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 3 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 3 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 3 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 3 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 3 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 3 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 3 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 3 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 3 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 3 finished in 0.0 seconds. ## Chain 4 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 4 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 4 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 4 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 4 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 4 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 4 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 4 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 4 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 4 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 4 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 4 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 4 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 4 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 4 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 4 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 4 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 4 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 4 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 4 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 4 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 4 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 4 finished in 0.0 seconds. ## ## All 4 chains finished successfully. ## Mean chain execution time: 0.0 seconds. ## Total execution time: 0.5 seconds. q1_prior_draws &lt;- cmd_draws(q1_prior_sample) mcmc_areas(q1_prior_draws, regex_pars = &#39;theta&#39;) mcmc_areas(q1_prior_draws, regex_pars = &#39;sigma&#39;) mcmc_areas(q1_prior_draws, regex_pars = &#39;beta_gender&#39;) mcmc_areas(q1_prior_draws, regex_pars = &#39;beta_discipline&#39;) 7.1.4 Model data { int&lt;lower=0&gt; N; int&lt;lower=0&gt; N_gender; int awards[N]; int applications [N]; int index_gender[N]; } parameters{ vector[N_gender] alpha; } model{ vector[N] p; alpha ~ normal(-1, 1); p = inv_logit(alpha[index_gender]); awards ~ binomial(applications, p); } # q1_stan &lt;- &#39;q1.stan&#39; # writeLines(readLines(q1_stan)) # q1_model &lt;- cmdstan_model(q1_stan) q1_sample &lt;- q1_model$sample(data = q1_data) ## Running MCMC with 4 sequential chains... ## ## Chain 1 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 1 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 1 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 1 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 1 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 1 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 1 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 1 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 1 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 1 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 1 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 1 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 1 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 1 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 1 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 1 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 1 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 1 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 1 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 1 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 1 finished in 0.0 seconds. ## Chain 2 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 2 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 2 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 2 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 2 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 2 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 2 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 2 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 2 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 2 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 2 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 2 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 2 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 2 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 2 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 2 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 2 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 2 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 2 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 2 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 2 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 2 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 2 finished in 0.0 seconds. ## Chain 3 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 3 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 3 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 3 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 3 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 3 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 3 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 3 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 3 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 3 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 3 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 3 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 3 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 3 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 3 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 3 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 3 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 3 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 3 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 3 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 3 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 3 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 3 finished in 0.0 seconds. ## Chain 4 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 4 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 4 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 4 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 4 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 4 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 4 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 4 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 4 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 4 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 4 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 4 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 4 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 4 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 4 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 4 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 4 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 4 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 4 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 4 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 4 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 4 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 4 finished in 0.0 seconds. ## ## All 4 chains finished successfully. ## Mean chain execution time: 0.0 seconds. ## Total execution time: 0.5 seconds. q1_draws &lt;- cmd_draws(q1_sample) mcmc_areas(q1_draws, regex_pars = &#39;alpha&#39;) q1_draws$dif_alpha &lt;- (inv.logit(q1_draws$`alpha[1]`) - inv.logit(q1_draws$`alpha[2]`)) * 100 mcmc_areas(q1_draws, regex_pars = &#39;dif_alpha&#39;) With discipline data { int&lt;lower=0&gt; N; int&lt;lower=0&gt; N_gender; int&lt;lower=0&gt; N_discipline; int awards[N]; int applications [N]; int index_gender[N]; int index_discipline[N]; } parameters{ vector[N_gender] alpha; vector[N_discipline] beta; } model{ vector[N] p; alpha ~ normal(-1, 1); beta ~ normal(0, 0.25); p = inv_logit(alpha[index_gender] + beta[index_discipline]); awards ~ binomial(applications, p); } # q1_stan &lt;- &#39;q1_discipline.stan&#39; # writeLines(readLines(q1_stan)) # q1_model_discipline &lt;- cmdstan_model(q1_stan) q1_sample &lt;- q1_model_discipline$sample(data = q1_data) ## Running MCMC with 4 sequential chains... ## ## Chain 1 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 1 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 1 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 1 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 1 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 1 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 1 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 1 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 1 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 1 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 1 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 1 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 1 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 1 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 1 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 1 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 1 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 1 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 1 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 1 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 1 finished in 0.1 seconds. ## Chain 2 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 2 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 2 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 2 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 2 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 2 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 2 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 2 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 2 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 2 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 2 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 2 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 2 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 2 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 2 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 2 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 2 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 2 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 2 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 2 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 2 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 2 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 2 finished in 0.1 seconds. ## Chain 3 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 3 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 3 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 3 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 3 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 3 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 3 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 3 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 3 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 3 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 3 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 3 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 3 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 3 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 3 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 3 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 3 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 3 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 3 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 3 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 3 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 3 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 3 finished in 0.1 seconds. ## Chain 4 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 4 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 4 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 4 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 4 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 4 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 4 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 4 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 4 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 4 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 4 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 4 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 4 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 4 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 4 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 4 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 4 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 4 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 4 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 4 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 4 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 4 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 4 finished in 0.1 seconds. ## ## All 4 chains finished successfully. ## Mean chain execution time: 0.1 seconds. ## Total execution time: 0.5 seconds. q1_draws &lt;- cmd_draws(q1_sample) mcmc_areas(q1_draws, regex_pars = &#39;alpha&#39;) mcmc_areas(q1_draws, regex_pars = &#39;beta&#39;) # Need to account for base rates to look at absolute rate # q1_draws$dif_alpha &lt;- (inv.logit(q1_draws$`alpha[1]`) - # inv.logit(q1_draws$`alpha[2]`)) * 100 # mcmc_areas(q1_draws, regex_pars = &#39;dif_alpha&#39;) # We can look at relative rates though q1_draws$dif_alpha_rel &lt;- q1_draws$`alpha[1]` - q1_draws$`alpha[2]` mcmc_areas(q1_draws, regex_pars = &#39;dif_alpha_rel&#39;) What is your causal interpretation? If NWO’s goal is to equalize rates of funding between the genders, what type of intervention would be most effective? Investigate departmental levels, since once this is included the relative differences are small. "],["homework-week-7.html", "8 Homework: Week 7 8.1 Question 1 8.2 Question 2", " 8 Homework: Week 7 2021-09-07 [updated: 2021-09-08] 8.0.1 Setup # Packages library(ggdag) library(dagitty) library(data.table) library(ggplot2) library(rethinking) library(cmdstanr) library(posterior) library(bayesplot) library(boot) # Functions dag_plot &lt;- function(dag) { stat &lt;- node_status(dag, FALSE) stat$data$status[is.na(stat$data$status)] &lt;- &#39;intermediate&#39; ggplot(stat, aes(x = x, y = y, xend = xend, yend = yend)) + geom_dag_point(aes(color = status), alpha = 0.5, size = 15) + geom_dag_edges() + labs(color = &#39;&#39;) + geom_dag_text(color = &#39;black&#39;) + scale_color_manual(values = list(&#39;exposure&#39; = &#39;#35608DFF&#39;, &#39;outcome&#39; = &#39;#22A884FF&#39;, &#39;intermediate&#39; = &#39;grey50&#39;)) + theme_void() } cmd_draws &lt;- function(model) { as_draws_df(model$draws()) } 8.0.2 Data data(Trolley) DT &lt;- data.table(Trolley) precis(DT) ## mean sd 5.5% 94.5% histogram ## case NaN NA NA NA ## response 4.20 1.91 1 7 ▃▂▁▃▁▇▁▅▁▅▁▅ ## order 16.50 9.29 2 31 ▇▅▇▇▅▇▂ ## id NaN NA NA NA ## age 37.49 14.23 18 61 ▂▇▅▇▅▇▅▅▃▅▂▁▁ ## male 0.57 0.49 0 1 ▅▁▁▁▁▁▁▁▁▇ ## edu NaN NA NA NA ## action 0.43 0.50 0 1 ▇▁▁▁▁▁▁▁▁▅ ## intention 0.47 0.50 0 1 ▇▁▁▁▁▁▁▁▁▇ ## contact 0.20 0.40 0 1 ▇▁▁▁▁▁▁▁▁▂ ## story NaN NA NA NA ## action2 0.63 0.48 0 1 ▃▁▁▁▁▁▁▁▁▇ Response: 1-7 integer, “how morally permissible the action to be taken (or not) is”. Categorical, ordered, but distances between categories is not metric or known. Logit = log-odds, cumulative logit = log-cumulative-odds. Both constrained between 0-1. Log-cumulative-odds for response 7 will be infinity since log(1/(1-1)) = infinity. Given this, we only need K-1 = 6 intercepts. 8.0.3 Model: ordered categorical outcome Probability of data: \\(R_{i} \\sim \\text{Ordered-logit}(\\phi_{i}, K)\\) Linear model: \\(\\phi_{i} = 0\\) Prior for each intercept: \\(K_{k} \\sim \\text{Normal}(0, 1.5)\\) register_knitr_engine(override = FALSE) data { int N; int K; int response[N]; int action[N]; int intention[N]; int contact[N]; } parameters { // Cut points are the positions of responses along cumulative odds ordered[K] cutpoints; real beta_action; real beta_intention; real beta_contact; } model { vector[N] phi; for (i in 1:N) { phi[i] = beta_action * action[i] + beta_contact * contact[i] + beta_intention * intention[i]; response[i] ~ ordered_logistic(phi[i], cutpoints); } cutpoints ~ normal(0, 1.5); beta_action ~ normal(0, 0.5); beta_contact ~ normal(0, 0.5); beta_intention ~ normal(0, 0.5); } # model1_stan &lt;- &#39;model1.stan&#39; # writeLines(readLines(model1_stan)) # model1 &lt;- cmdstan_model(model1_stan, cpp_options = list(stan_threads = TRUE)) model_data &lt;- c( as.list(DT[, .(response, action, intention, contact)]), N = DT[, .N], K = DT[, uniqueN(response) - 1] ) model1_sample &lt;- model1$sample( data = model_data, chains = 4, parallel_chains = 4, threads_per_chain = 4 ) ## Warning: &#39;threads_per_chain&#39; is set but the model was not compiled with &#39;cpp_options = ## list(stan_threads = TRUE)&#39; so &#39;threads_per_chain&#39; will have no effect! ## Running MCMC with 4 parallel chains... ## ## Chain 1 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -3975.82, but should be greater than the previous element, -3975.82 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -3975.66, but should be greater than the previous element, -3975.66 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -993.493, but should be greater than the previous element, -993.493 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -247.693, but should be greater than the previous element, -247.693 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -60.8856, but should be greater than the previous element, -60.8856 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -14.2358, but should be greater than the previous element, -14.2358 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -710081, but should be greater than the previous element, -710081 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -20280.7, but should be greater than the previous element, -20280.7 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -196.323, but should be greater than the previous element, -196.323 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 2 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -983.903, but should be greater than the previous element, -983.903 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -984.776, but should be greater than the previous element, -984.776 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -245.894, but should be greater than the previous element, -245.894 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -62.1734, but should be greater than the previous element, -62.1734 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -10665.2, but should be greater than the previous element, -10665.2 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -300.803, but should be greater than the previous element, -300.803 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 3 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -3746.74, but should be greater than the previous element, -3746.74 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -3745.82, but should be greater than the previous element, -3745.82 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -937.247, but should be greater than the previous element, -937.247 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -235.113, but should be greater than the previous element, -235.113 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -59.4489, but should be greater than the previous element, -59.4489 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -15.5856, but should be greater than the previous element, -15.5856 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -566145, but should be greater than the previous element, -566145 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -16176, but should be greater than the previous element, -16176 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -158.195, but should be greater than the previous element, -158.195 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 4 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -2267.09, but should be greater than the previous element, -2267.09 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -2264.86, but should be greater than the previous element, -2264.86 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -566.279, but should be greater than the previous element, -566.279 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -142.273, but should be greater than the previous element, -142.273 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is -35.8649, but should be greater than the previous element, -35.8649 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is inf, but should be greater than the previous element, inf (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is inf, but should be greater than the previous element, inf (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 5 is 4.85733e+21, but should be greater than the previous element, 4.85733e+21 (in &#39;/tmp/RtmpPmFSHM/model-581fffb4f.stan&#39;, line 21, column 2 to column 52) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 3 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 1 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 4 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 2 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 3 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 1 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 4 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 2 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 1 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 3 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 4 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 2 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 3 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 1 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 4 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 2 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 3 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 1 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 4 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 1 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 2 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 3 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 4 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 1 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 1 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 2 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 2 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 3 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 3 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 4 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 4 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 2 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 3 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 1 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 4 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 2 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 3 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 3 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 1 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 4 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 4 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 2 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 2 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 3 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 1 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 4 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 2 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 3 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 1 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 4 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 2 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 3 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 1 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 4 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 2 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 3 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 1 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 4 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 2 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 3 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 1 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 4 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 2 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 3 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 1 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 4 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 2 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 3 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 1 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 4 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 2 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 3 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 1 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 4 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 2 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 3 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 1 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 4 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 2 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 3 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 3 finished in 186.5 seconds. ## Chain 4 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 4 finished in 187.3 seconds. ## Chain 1 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 1 finished in 188.6 seconds. ## Chain 2 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 2 finished in 190.2 seconds. ## ## All 4 chains finished successfully. ## Mean chain execution time: 188.1 seconds. ## Total execution time: 190.4 seconds. model1_draws &lt;- cmd_draws(model1_sample) mcmc_areas(model1_draws, regex_pars = &#39;beta&#39;) data { int N; int K; int response[N]; int action[N]; int intention[N]; int contact[N]; } parameters { // Cut points are the positions of responses along cumulative odds ordered[K] cutpoints; real beta_action; real beta_intention; real beta_contact; real beta_intention_contact; real beta_intention_action; } model { vector[N] phi; for (i in 1:N) { phi[i] = beta_action * action[i] + beta_contact * contact[i] + beta_intention * intention[i] + beta_intention_contact * intention[i] * contact[i] + beta_intention_action * intention[i] * action[i] ; response[i] ~ ordered_logistic(phi[i], cutpoints); } cutpoints ~ normal(0, 1.5); beta_action ~ normal(0, 0.5); beta_contact ~ normal(0, 0.5); beta_intention ~ normal(0, 0.5); } # model1_interactions_stan &lt;- &#39;model1_interactions.stan&#39; # writeLines(readLines(model1_interactions_stan)) # model1_interactions &lt;- cmdstan_model(model1_interactions_stan, cpp_options = list(stan_threads = TRUE)) model_data &lt;- c( as.list(DT[, .(response, action, intention, contact)]), N = DT[, .N], K = DT[, uniqueN(response) - 1] ) model1_interactions_sample &lt;- model1_interactions$sample( data = model_data, chains = 4, parallel_chains = 4, threads_per_chain = 4 ) ## Warning: &#39;threads_per_chain&#39; is set but the model was not compiled with &#39;cpp_options = ## list(stan_threads = TRUE)&#39; so &#39;threads_per_chain&#39; will have no effect! ## Running MCMC with 4 parallel chains... ## ## Chain 1 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -2090.46, but should be greater than the previous element, -2090.46 (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -2090.17, but should be greater than the previous element, -2090.17 (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -521.807, but should be greater than the previous element, -521.807 (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is -130.022, but should be greater than the previous element, -130.022 (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is -31.8243, but should be greater than the previous element, -31.8243 (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is inf, but should be greater than the previous element, inf (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is inf, but should be greater than the previous element, inf (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 5 is 6.77656e+19, but should be greater than the previous element, 6.77656e+19 (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 2 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -4036.53, but should be greater than the previous element, -4036.53 (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -4036.74, but should be greater than the previous element, -4036.74 (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -1006.6, but should be greater than the previous element, -1006.6 (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -250.659, but should be greater than the previous element, -250.659 (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is -61.196, but should be greater than the previous element, -61.196 (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is -14.0372, but should be greater than the previous element, -14.0372 (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -506238, but should be greater than the previous element, -506238 (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -14457.5, but should be greater than the previous element, -14457.5 (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 3 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -3470.77, but should be greater than the previous element, -3470.77 (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -3471.19, but should be greater than the previous element, -3471.19 (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -867.751, but should be greater than the previous element, -867.751 (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -217.734, but should be greater than the previous element, -217.734 (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -55.0455, but should be greater than the previous element, -55.0455 (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is inf, but should be greater than the previous element, inf (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is inf, but should be greater than the previous element, inf (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 5 is 2.07693e+15, but should be greater than the previous element, 2.07693e+15 (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 4 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -4172.54, but should be greater than the previous element, -4172.54 (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -4170.06, but should be greater than the previous element, -4170.06 (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -1041.64, but should be greater than the previous element, -1041.64 (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -259.079, but should be greater than the previous element, -259.079 (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -63.6723, but should be greater than the previous element, -63.6723 (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -14.6763, but should be greater than the previous element, -14.6763 (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is inf, but should be greater than the previous element, inf (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is inf, but should be greater than the previous element, inf (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is 762828, but should be greater than the previous element, 762828 (in &#39;/tmp/RtmpPmFSHM/model-581507a1631.stan&#39;, line 24, column 2 to column 52) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 2 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 1 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 3 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 4 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 1 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 2 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 4 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 3 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 1 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 2 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 4 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 3 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 1 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 2 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 4 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 3 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 1 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 2 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 4 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 3 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 1 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 2 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 4 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 3 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 1 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 2 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 4 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 3 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 1 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 2 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 4 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 3 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 1 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 2 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 4 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 3 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 1 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 2 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 2 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 4 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 4 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 3 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 3 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 1 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 2 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 4 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 1 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 3 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 2 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 4 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 1 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 2 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 3 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 4 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 1 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 2 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 3 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 4 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 1 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 2 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 4 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 3 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 1 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 2 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 4 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 1 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 3 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 2 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 4 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 1 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 2 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 3 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 4 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 1 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 2 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 3 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 4 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 1 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 1 finished in 265.1 seconds. ## Chain 2 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 2 finished in 266.8 seconds. ## Chain 4 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 4 finished in 269.4 seconds. ## Chain 3 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 3 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 3 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 3 finished in 295.6 seconds. ## ## All 4 chains finished successfully. ## Mean chain execution time: 274.2 seconds. ## Total execution time: 296.0 seconds. model1_interactions_draws &lt;- cmd_draws(model1_interactions_sample) mcmc_areas(model1_interactions_draws, regex_pars = &#39;beta&#39;) mcmc_areas(model1_interactions_draws, regex_pars = &#39;cut&#39;, transformations = inv.logit) + xlim(0, 1) ## Scale for &#39;x&#39; is already present. Adding another scale for &#39;x&#39;, which will replace the ## existing scale. 8.0.4 Model: ordered categorical predictors Probability of data: \\(R_{i} \\sim \\text{Ordered-logit}(\\phi_{i}, K)\\) Linear model: \\(\\phi_{i} = \\beta_{E} \\sum_{j=0}^{E_{i}-1}\\delta_{j} + \\beta{A_{i}}A_{i} + \\beta{I_{i}}I_{i} + \\beta{C_{i}}C_{i}\\) Prior for each intercept: \\(K_{k} \\sim \\text{Normal}(0, 1.5)\\) Prior for each \\(\\beta\\): \\(\\beta_{A}, \\beta_{I}, \\beta_{C}, \\beta_{E}K_{k} \\sim \\text{Normal}(0, 1)\\) Prior for the \\(\\delta\\) vector: \\(\\delta \\sim \\text{Dirichlet}(\\alpha)\\) Dirichlet distribution = multivariate extension of the beta distribution. Probabilities between zero and one, that all sum to one. It is parameterized by pseudo-counts of observations. The intercept takes the first category, so we add 0 to the sequence of Make sure to reorder education levels data { int N; int K; int N_edu; int response[N]; int action[N]; int intention[N]; int contact[N]; int education[N]; vector[N_edu - 1] alpha; } parameters { // Cut points are the positions of responses along cumulative odds ordered[K] cutpoints; real beta_action; real beta_intention; real beta_contact; real beta_education; // Vector N reals that sum to 1 simplex[7] delta; } model { vector[N] phi; vector[N_edu] delta_j; delta ~ dirichlet(alpha); delta_j = append_row(0, delta); for (i in 1:N) { // add beta education * sum delta j, up to current i&#39;s education phi[i] = beta_education * sum(delta_j[1:education[i]]) + beta_action * action[i] + beta_contact * contact[i] + beta_intention * intention[i]; response[i] ~ ordered_logistic(phi[i], cutpoints); } cutpoints ~ normal(0, 1.5); beta_action ~ normal(0, 1); beta_contact ~ normal(0, 1); beta_intention ~ normal(0, 1); beta_education ~ normal(0, 1); } # model2_stan &lt;- &#39;model2.stan&#39; # writeLines(readLines(model2_stan)) # model2 &lt;- cmdstan_model(model2_stan, cpp_options = list(stan_threads = TRUE)) edu_levels &lt;- c(6, 1, 8, 4, 7, 2, 5, 3) DT[, education := as.integer(edu_levels[edu])] model_data &lt;- c( as.list(DT[, .(response, action, intention, contact, education)]), N = DT[, .N], K = DT[, uniqueN(response) - 1], N_edu = DT[, uniqueN(education)], alpha = list(rep(2, 7)) ) model2_sample &lt;-model2$sample( data = model_data, chains = 4, parallel_chains = 4, threads_per_chain = 4 ) ## Warning: &#39;threads_per_chain&#39; is set but the model was not compiled with ## &#39;cpp_options = list(stan_threads = TRUE)&#39; so &#39;threads_per_chain&#39; will have no ## effect! ## Running MCMC with 4 parallel chains... ## ## Chain 1 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -3536.27, but should be greater than the previous element, -3536.27 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -3538.62, but should be greater than the previous element, -3538.62 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -883.714, but should be greater than the previous element, -883.714 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -220.916, but should be greater than the previous element, -220.916 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -55.4413, but should be greater than the previous element, -55.4413 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -64626.6, but should be greater than the previous element, -64626.6 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -1290, but should be greater than the previous element, -1290 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 2 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -3668.57, but should be greater than the previous element, -3668.57 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -3670.11, but should be greater than the previous element, -3670.11 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -916.117, but should be greater than the previous element, -916.117 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -228.625, but should be greater than the previous element, -228.625 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -56.6737, but should be greater than the previous element, -56.6737 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -13.7651, but should be greater than the previous element, -13.7651 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is inf, but should be greater than the previous element, inf (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is inf, but should be greater than the previous element, inf (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 5 is 6.23826e+26, but should be greater than the previous element, 6.23826e+26 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 3 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -2606.87, but should be greater than the previous element, -2606.87 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -2606.94, but should be greater than the previous element, -2606.94 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -650.912, but should be greater than the previous element, -650.912 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -162.97, but should be greater than the previous element, -162.97 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -40.3174, but should be greater than the previous element, -40.3174 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -209470, but should be greater than the previous element, -209470 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -5983.11, but should be greater than the previous element, -5983.11 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -58.5201, but should be greater than the previous element, -58.5201 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 4 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -4184.54, but should be greater than the previous element, -4184.54 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -4185.83, but should be greater than the previous element, -4185.83 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -1044.44, but should be greater than the previous element, -1044.44 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -259.502, but should be greater than the previous element, -259.502 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -63.8404, but should be greater than the previous element, -63.8404 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 5 is -14.6049, but should be greater than the previous element, -14.6049 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -175323, but should be greater than the previous element, -175323 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -3495.6, but should be greater than the previous element, -3495.6 (in &#39;/tmp/RtmpRGOmti/model-68612194ce94.stan&#39;, line 36, column 4 to column 54) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 2 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 1 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 4 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 3 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 2 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 4 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 1 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 2 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 3 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 4 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 1 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 2 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 4 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 3 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 1 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 2 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 3 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 4 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 2 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 1 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 4 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 3 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 2 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 1 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 4 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 3 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 2 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 1 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 4 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 3 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 2 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 1 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 4 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 3 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 2 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 2 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 1 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 4 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 4 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 3 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 2 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 1 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 3 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 3 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 4 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 2 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 3 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 1 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 4 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 3 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 2 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 1 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 4 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 3 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 2 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 1 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 3 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 4 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 2 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 3 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 1 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 4 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 2 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 3 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 1 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 4 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 2 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 3 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 1 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 3 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 4 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 2 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 3 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 1 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 2 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 4 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 3 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 3 finished in 733.5 seconds. ## Chain 1 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 2 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 2 finished in 746.8 seconds. ## Chain 4 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 1 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 4 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 4 finished in 779.5 seconds. ## Chain 1 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 1 finished in 807.2 seconds. ## ## All 4 chains finished successfully. ## Mean chain execution time: 766.7 seconds. ## Total execution time: 807.4 seconds. model2_draws &lt;- cmd_draws(model2_sample) mcmc_areas(model2_draws, regex_pars = &#39;beta&#39;) mcmc_areas(model2_draws, regex_pars = &#39;delta&#39;) mcmc_areas(model2_draws, regex_pars = &#39;cut&#39;, transformations = inv.logit) + xlim(0, 1) ## Scale for &#39;x&#39; is already present. Adding another scale for &#39;x&#39;, which will ## replace the existing scale. 8.1 Question 1 In the Trolley data—data(Trolley)—we saw how education level (modeled as an ordered category) is associated with responses. Is this association causal? One plausible confound is that education is also associated with age, through a causal process: People are older when they finish school than when they begin it. Reconsider the Trolley data in this light. Draw a DAG that represents hypothetical causal relationships among response, education, and age. dag &lt;- dagify( response ~ education + age + action + intention + contact, education ~ age, contact ~ action, exposure = &#39;education&#39;, outcome = &#39;response&#39; ) dag_plot(dag) adjustmentSets(dag, exposure = &#39;education&#39;, outcome = &#39;response&#39;, effect = &#39;total&#39; ) ## { age } Which statistical model or models do you need to evaluate the causal influence of education on responses? Fit these models to the trolley data. What do you conclude about the causal relationships among these three variables? data { int N; int K; int N_edu; int response[N]; int action[N]; int intention[N]; int contact[N]; int education[N]; real age[N]; vector[N_edu - 1] alpha; } parameters { // Cut points are the positions of responses along cumulative odds ordered[K] cutpoints; real beta_action; real beta_intention; real beta_contact; real beta_education; real beta_age; // Vector N reals that sum to 1 simplex[7] delta; } model { vector[N] phi; vector[N_edu] delta_j; delta ~ dirichlet(alpha); delta_j = append_row(0, delta); for (i in 1:N) { // add beta education * sum delta j, up to current i&#39;s education phi[i] = beta_education * sum(delta_j[1:education[i]]) + beta_action * action[i] + beta_contact * contact[i] + beta_age * age[i] + beta_intention * intention[i]; response[i] ~ ordered_logistic(phi[i], cutpoints); } cutpoints ~ normal(0, 1.5); beta_action ~ normal(0, 1); beta_contact ~ normal(0, 1); beta_intention ~ normal(0, 1); beta_education ~ normal(0, 1); beta_age ~ normal(0, 1); } # model2_age_stan &lt;- &#39;model2_age.stan&#39; # writeLines(readLines(model2_age_stan)) # model2_age &lt;- cmdstan_model(model2_age_stan, cpp_options = list(stan_threads = TRUE)) edu_levels &lt;- c(6, 1, 8, 4, 7, 2, 5, 3) DT[, education := as.integer(edu_levels[edu])] model_data &lt;- c( as.list(DT[, .(response, action, intention, contact, education, age = as.numeric(scale(age)))]), N = DT[, .N], K = DT[, uniqueN(response) - 1], N_edu = DT[, uniqueN(education)], alpha = list(rep(2, 7)) ) model2_sample &lt;- model2_age$sample( data = model_data, chains = 4, parallel_chains = 4, threads_per_chain = 4 ) ## Warning: &#39;threads_per_chain&#39; is set but the model was not compiled with ## &#39;cpp_options = list(stan_threads = TRUE)&#39; so &#39;threads_per_chain&#39; will have no ## effect! ## Running MCMC with 4 parallel chains... ## ## Chain 1 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -3774.27, but should be greater than the previous element, -3774.27 (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -3774.45, but should be greater than the previous element, -3774.45 (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -942.907, but should be greater than the previous element, -942.907 (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -234.786, but should be greater than the previous element, -234.786 (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is -57.4411, but should be greater than the previous element, -57.4411 (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -158086, but should be greater than the previous element, -158086 (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -3448.5, but should be greater than the previous element, -3448.5 (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 2 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -254.425, but should be greater than the previous element, -254.425 (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -252.53, but should be greater than the previous element, -252.53 (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 5 is 4.44269e+94, but should be greater than the previous element, 4.44269e+94 (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 5 is 1.18146e+23, but should be greater than the previous element, 1.18146e+23 (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 5 is 165910, but should be greater than the previous element, 165910 (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is inf, but should be greater than the previous element, inf (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 3 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -4070.36, but should be greater than the previous element, -4070.36 (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -4070.88, but should be greater than the previous element, -4070.88 (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -1016.39, but should be greater than the previous element, -1016.39 (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -252.758, but should be greater than the previous element, -252.758 (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -62.038, but should be greater than the previous element, -62.038 (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is -14.3382, but should be greater than the previous element, -14.3382 (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 4 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is -1163.7, but should be greater than the previous element, -1163.7 (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is -1164.52, but should be greater than the previous element, -1164.52 (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is -291.31, but should be greater than the previous element, -291.31 (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is -74.2155, but should be greater than the previous element, -74.2155 (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is -19.9489, but should be greater than the previous element, -19.9489 (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is inf, but should be greater than the previous element, inf (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is inf, but should be greater than the previous element, inf (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 5 is 1.4506e+22, but should be greater than the previous element, 1.4506e+22 (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is inf, but should be greater than the previous element, inf (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 5 is 1.58694e+24, but should be greater than the previous element, 1.58694e+24 (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -792710, but should be greater than the previous element, -792710 (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -22639.6, but should be greater than the previous element, -22639.6 (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -219.351, but should be greater than the previous element, -219.351 (in &#39;/tmp/RtmpRGOmti/model-6861512e622a.stan&#39;, line 39, column 4 to column 54) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 2 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 3 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 1 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 4 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 3 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 2 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 4 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 1 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 3 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 2 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 4 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 1 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 2 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 3 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 1 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 4 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 3 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 2 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 1 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 4 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 3 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 2 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 4 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 1 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 3 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 1 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 4 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 2 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 1 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 4 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 3 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 2 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 1 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 4 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 3 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 3 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 2 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 4 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 4 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 1 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 2 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 2 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 3 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 4 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 1 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 2 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 3 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 4 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 2 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 1 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 3 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 2 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 4 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 1 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 2 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 3 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 4 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 1 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 2 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 3 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 4 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 2 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 1 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 3 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 4 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 2 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 1 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 2 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 3 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 4 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 1 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 2 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 3 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 4 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 2 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 2 finished in 529.1 seconds. ## Chain 1 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 3 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 4 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 1 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 4 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 4 finished in 560.2 seconds. ## Chain 3 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 3 finished in 560.8 seconds. ## Chain 1 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 1 finished in 573.7 seconds. ## ## All 4 chains finished successfully. ## Mean chain execution time: 555.9 seconds. ## Total execution time: 573.8 seconds. model2_draws &lt;- cmd_draws(model2_sample) mcmc_areas(model2_draws, regex_pars = &#39;beta&#39;) mcmc_areas(model2_draws, regex_pars = &#39;delta&#39;) mcmc_areas(model2_draws, regex_pars = &#39;cut&#39;, transformations = inv.logit) + xlim(0, 1) ## Scale for &#39;x&#39; is already present. Adding another scale for &#39;x&#39;, which will ## replace the existing scale. 8.2 Question 2 Consider one more variable in the Trolley data: Gender. Suppose that gender might influence education as well as response directly. Draw the DAG now that includes response, education, age, and gender. Using only the DAG, is it possible that the inferences from Problem 1 are con founded by gender? If so, define any additional models you need to infer the causal influence of education on response. What do you conclude? dag &lt;- dagify( response ~ education + age + gender + action + intention + contact, education ~ age, education ~ gender, contact ~ action, exposure = &#39;education&#39;, outcome = &#39;response&#39; ) dag_plot(dag) adjustmentSets(dag, exposure = &#39;education&#39;, outcome = &#39;response&#39;, effect = &#39;total&#39; ) ## { age, gender } data { int N; int K; int N_edu; int response[N]; int action[N]; int intention[N]; int contact[N]; int education[N]; real age[N]; int gender[N]; vector[N_edu - 1] alpha; } parameters { // Cut points are the positions of responses along cumulative odds ordered[K] cutpoints; real beta_action; real beta_intention; real beta_contact; real beta_education; real beta_age; real beta_gender; // Vector N reals that sum to 1 simplex[7] delta; } model { vector[N] phi; vector[N_edu] delta_j; delta ~ dirichlet(alpha); delta_j = append_row(0, delta); for (i in 1:N) { // add beta education * sum delta j, up to current i&#39;s education phi[i] = beta_education * sum(delta_j[1:education[i]]) + beta_action * action[i] + beta_contact * contact[i] + beta_age * age[i] + beta_gender * gender[i] + beta_intention * intention[i]; response[i] ~ ordered_logistic(phi[i], cutpoints); } cutpoints ~ normal(0, 1.5); beta_action ~ normal(0, 1); beta_contact ~ normal(0, 1); beta_intention ~ normal(0, 1); beta_education ~ normal(0, 1); beta_age ~ normal(0, 1); beta_gender ~ normal(0, 1); } # model2_gender_stan &lt;- &#39;model2_gender.stan&#39; # writeLines(readLines(model2_gender_stan)) # model2_gender &lt;- cmdstan_model(model2_gender_stan, cpp_options = list(stan_threads = TRUE)) edu_levels &lt;- c(6, 1, 8, 4, 7, 2, 5, 3) DT[, education := as.integer(edu_levels[edu])] model_data &lt;- c( as.list(DT[, .(response, action, intention, contact, education, age = as.numeric(scale(age)), gender = ifelse(male == 1, 0, 1))]), N = DT[, .N], K = DT[, uniqueN(response) - 1], N_edu = DT[, uniqueN(education)], alpha = list(rep(2, 7)) ) model2_gender_sample &lt;- model2_gender$sample( data = model_data, chains = 4, parallel_chains = 4, threads_per_chain = 4 ) ## Warning: &#39;threads_per_chain&#39; is set but the model was not compiled with ## &#39;cpp_options = list(stan_threads = TRUE)&#39; so &#39;threads_per_chain&#39; will have no ## effect! ## Running MCMC with 4 parallel chains... ## ## Chain 1 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -2324.5, but should be greater than the previous element, -2324.5 (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -2324.78, but should be greater than the previous element, -2324.78 (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -581.396, but should be greater than the previous element, -581.396 (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -146.306, but should be greater than the previous element, -146.306 (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -37.2032, but should be greater than the previous element, -37.2032 (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -9.91262, but should be greater than the previous element, -9.91262 (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -165253, but should be greater than the previous element, -165253 (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -4719.28, but should be greater than the previous element, -4719.28 (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -47.0655, but should be greater than the previous element, -47.0655 (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 2 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -3013.58, but should be greater than the previous element, -3013.58 (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -3014.92, but should be greater than the previous element, -3014.92 (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -753.918, but should be greater than the previous element, -753.918 (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -188.41, but should be greater than the previous element, -188.41 (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is -47.3544, but should be greater than the previous element, -47.3544 (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is -11.9916, but should be greater than the previous element, -11.9916 (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is inf, but should be greater than the previous element, inf (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is inf, but should be greater than the previous element, inf (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 6 is 8.03248e+23, but should be greater than the previous element, 8.03248e+23 (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 3 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -2095.29, but should be greater than the previous element, -2095.29 (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -2095.71, but should be greater than the previous element, -2095.71 (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -524.599, but should be greater than the previous element, -524.599 (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -132.174, but should be greater than the previous element, -132.174 (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 4 is -32.2111, but should be greater than the previous element, -32.2111 (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is inf, but should be greater than the previous element, inf (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is inf, but should be greater than the previous element, inf (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 5 is 4.50574e+11, but should be greater than the previous element, 4.50574e+11 (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 4 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -2884.03, but should be greater than the previous element, -2884.03 (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -2886.16, but should be greater than the previous element, -2886.16 (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -721.576, but should be greater than the previous element, -721.576 (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -180.649, but should be greater than the previous element, -180.649 (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -45.7997, but should be greater than the previous element, -45.7997 (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is inf, but should be greater than the previous element, inf (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 3 is inf, but should be greater than the previous element, inf (in &#39;/tmp/Rtmp2apNfn/model-882773fa8dbf.stan&#39;, line 42, column 4 to column 54) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 1 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 2 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 4 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 3 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 1 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 2 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 4 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 1 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 3 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 2 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 1 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 4 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 3 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 2 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 1 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 4 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 3 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 2 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 1 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 4 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 3 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 1 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 2 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 4 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 3 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 1 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 2 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 4 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 1 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 3 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 2 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 4 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 3 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 2 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 1 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 4 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 3 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 1 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 2 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 2 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 4 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 4 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 3 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 3 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 1 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 4 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 2 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 3 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 1 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 4 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 3 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 2 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 1 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 4 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 3 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 2 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 4 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 1 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 3 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 4 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 1 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 2 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 3 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 4 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 1 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 2 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 3 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 4 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 1 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 3 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 4 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 2 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 1 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 3 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 4 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 1 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 1 finished in 709.1 seconds. ## Chain 2 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 3 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 4 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 4 finished in 721.1 seconds. ## Chain 3 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 3 finished in 739.7 seconds. ## Chain 2 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 2 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 2 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 2 finished in 799.4 seconds. ## ## All 4 chains finished successfully. ## Mean chain execution time: 742.3 seconds. ## Total execution time: 799.5 seconds. model2_gender_draws &lt;- cmd_draws(model2_gender_sample) mcmc_areas(model2_gender_draws, regex_pars = &#39;beta&#39;) mcmc_areas(model2_gender_draws, regex_pars = &#39;delta&#39;) mcmc_areas(model2_gender_draws, regex_pars = &#39;cut&#39;, transformations = inv.logit) + xlim(0, 1) ## Scale for &#39;x&#39; is already present. Adding another scale for &#39;x&#39;, which will ## replace the existing scale. "],["homework-week-8.html", "9 Homework: Week 8 9.1 Question 1 9.2 Question 2", " 9 Homework: Week 8 2021-09-08 [updated: 2021-09-08] 9.0.1 Setup # Packages library(ggdag) library(dagitty) library(data.table) library(ggplot2) library(rethinking) library(cmdstanr) library(posterior) library(bayesplot) library(boot) # Functions dag_plot &lt;- function(dag) { stat &lt;- node_status(dag, FALSE) stat$data$status[is.na(stat$data$status)] &lt;- &#39;intermediate&#39; ggplot(stat, aes(x = x, y = y, xend = xend, yend = yend)) + geom_dag_point(aes(color = status), alpha = 0.5, size = 15) + geom_dag_edges() + labs(color = &#39;&#39;) + geom_dag_text(color = &#39;black&#39;) + scale_color_manual(values = list(&#39;exposure&#39; = &#39;#35608DFF&#39;, &#39;outcome&#39; = &#39;#22A884FF&#39;, &#39;intermediate&#39; = &#39;grey50&#39;)) + theme_void() } cmd_draws &lt;- function(model) { as_draws_df(model$draws()) } 9.1 Question 1 9.1.1 Data data(reedfrogs) DT &lt;- data.table(reedfrogs) precis(DT) ## mean sd 5.5% 94.5% histogram ## density 23.33 10.38 10.00 35 ▇▁▁▁▁▁▁▇▁▁▁▁▇ ## pred NaN NA NA NA ## size NaN NA NA NA ## surv 16.31 9.88 4.58 33 ▂▇▂▁▃▁▃ ## propsurv 0.72 0.27 0.29 1 ▁▁▃▁▁▂▁▅▇ register_knitr_engine(override = FALSE) data { int N; int survival[N]; int density[N]; int tank[N]; } parameters { real sigma; real alpha[N]; real alpha_bar; } transformed parameters { vector[N] p; for (i in 1:N) { p[i] = inv_logit(alpha[i]); } } model { alpha ~ normal(alpha_bar, sigma); sigma ~ exponential(1); for (i in 1:N) { survival[i] ~ binomial(density[i], p[i]); } } # model_frogs_1_stan &lt;- &#39;model_frogs_1.stan&#39; # writeLines(readLines(model_frogs_1_stan)) # model_frogs_1 &lt;- cmdstan_model(model_frogs_1_stan, cpp_options = list(stan_threads = TRUE)) model_data &lt;- c( as.list(DT[, .( survival = surv, density, predation = as.integer(pred), size = as.integer(size), tank = seq.int(.N) )]), N = DT[, .N] ) model_frogs_1_sample &lt;- model_frogs_1$sample( data = model_data, chains = 4, parallel_chains = 4, threads_per_chain = 4 ) ## Warning: &#39;threads_per_chain&#39; is set but the model was not compiled with ## &#39;cpp_options = list(stan_threads = TRUE)&#39; so &#39;threads_per_chain&#39; will have no ## effect! ## Running MCMC with 4 parallel chains... ## Chain 1 Rejecting initial value: ## Chain 1 Error evaluating the log probability at the initial value. ## Chain 1 Exception: normal_lpdf: Scale parameter is -0.302923, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b5b748bd7.stan&#39;, line 20, column 1 to column 34) ## Chain 1 Exception: normal_lpdf: Scale parameter is -0.302923, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b5b748bd7.stan&#39;, line 20, column 1 to column 34) ## Chain 1 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 1 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 1 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 1 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 1 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 1 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 1 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 1 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 1 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 1 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 1 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 1 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 1 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 1 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 1 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 1 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: normal_lpdf: Scale parameter is -0.00566913, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b5b748bd7.stan&#39;, line 20, column 1 to column 34) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: normal_lpdf: Scale parameter is -3.22946, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b5b748bd7.stan&#39;, line 20, column 1 to column 34) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 2 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 2 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 2 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 2 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 2 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 2 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 2 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 2 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 2 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 2 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 2 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 2 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 2 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 2 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 2 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 2 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: normal_lpdf: Scale parameter is -20.7527, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b5b748bd7.stan&#39;, line 20, column 1 to column 34) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: normal_lpdf: Scale parameter is -1.65316, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b5b748bd7.stan&#39;, line 20, column 1 to column 34) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 3 Rejecting initial value: ## Chain 3 Error evaluating the log probability at the initial value. ## Chain 3 Exception: normal_lpdf: Scale parameter is -1.64371, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b5b748bd7.stan&#39;, line 20, column 1 to column 34) ## Chain 3 Exception: normal_lpdf: Scale parameter is -1.64371, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b5b748bd7.stan&#39;, line 20, column 1 to column 34) ## Chain 3 Rejecting initial value: ## Chain 3 Error evaluating the log probability at the initial value. ## Chain 3 Exception: normal_lpdf: Scale parameter is -0.820706, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b5b748bd7.stan&#39;, line 20, column 1 to column 34) ## Chain 3 Exception: normal_lpdf: Scale parameter is -0.820706, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b5b748bd7.stan&#39;, line 20, column 1 to column 34) ## Chain 3 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 3 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 3 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 3 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 3 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 3 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 3 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 3 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 3 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 3 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 3 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 3 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 3 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 3 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: normal_lpdf: Scale parameter is -0.592547, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b5b748bd7.stan&#39;, line 20, column 1 to column 34) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 4 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 4 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 4 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 4 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 4 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 4 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 4 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 4 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 4 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 4 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 4 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 4 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 4 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 4 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 4 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: normal_lpdf: Scale parameter is -0.0720808, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b5b748bd7.stan&#39;, line 20, column 1 to column 34) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: normal_lpdf: Scale parameter is -2.9413, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b5b748bd7.stan&#39;, line 20, column 1 to column 34) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 4 Exception: normal_lpdf: Scale parameter is -0.927967, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b5b748bd7.stan&#39;, line 20, column 1 to column 34) ## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 4 ## Chain 1 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 1 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 1 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 1 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 1 finished in 0.2 seconds. ## Chain 2 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 2 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 2 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 2 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 2 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 2 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 2 finished in 0.2 seconds. ## Chain 3 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 3 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 3 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 3 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 3 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 3 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 3 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 3 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 4 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 4 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 4 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 4 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 4 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 4 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 4 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 3 finished in 0.2 seconds. ## Chain 4 finished in 0.3 seconds. ## ## All 4 chains finished successfully. ## Mean chain execution time: 0.2 seconds. ## Total execution time: 0.4 seconds. model_frogs_1_draws &lt;- cmd_draws(model_frogs_1_sample) mcmc_areas(model_frogs_1_draws, regex_pars = &#39;alpha&#39;) mcmc_areas(model_frogs_1_draws, regex_pars = &#39;p\\\\[&#39;) data { int N; int survival[N]; int density[N]; int tank[N]; int predation[N]; } parameters { real sigma; real alpha[N]; real alpha_bar; real beta_predation; } transformed parameters { vector[N] p; for (i in 1:N) { p[i] = inv_logit(alpha[i] + beta_predation * predation[i]); } } model { alpha ~ normal(alpha_bar, sigma); beta_predation ~ normal(0, 0.5); sigma ~ exponential(1); for (i in 1:N) { survival[i] ~ binomial(density[i], p[i]); } } # model_frogs_2_stan &lt;- &#39;model_frogs_2.stan&#39; # writeLines(readLines(model_frogs_2_stan)) # model_frogs_2 &lt;- cmdstan_model(model_frogs_2_stan, cpp_options = list(stan_threads = TRUE)) model_frogs_2_sample &lt;- model_frogs_2$sample( data = model_data, chains = 4, parallel_chains = 4, threads_per_chain = 4 ) ## Warning: &#39;threads_per_chain&#39; is set but the model was not compiled with ## &#39;cpp_options = list(stan_threads = TRUE)&#39; so &#39;threads_per_chain&#39; will have no ## effect! ## Running MCMC with 4 parallel chains... ## ## Chain 1 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 1 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 1 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 1 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 1 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 1 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 2 Rejecting initial value: ## Chain 2 Error evaluating the log probability at the initial value. ## Chain 2 Exception: normal_lpdf: Scale parameter is -0.934527, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b3e802a7a.stan&#39;, line 22, column 1 to column 34) ## Chain 2 Exception: normal_lpdf: Scale parameter is -0.934527, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b3e802a7a.stan&#39;, line 22, column 1 to column 34) ## Chain 2 Rejecting initial value: ## Chain 2 Error evaluating the log probability at the initial value. ## Chain 2 Exception: normal_lpdf: Scale parameter is -0.222269, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b3e802a7a.stan&#39;, line 22, column 1 to column 34) ## Chain 2 Exception: normal_lpdf: Scale parameter is -0.222269, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b3e802a7a.stan&#39;, line 22, column 1 to column 34) ## Chain 2 Rejecting initial value: ## Chain 2 Error evaluating the log probability at the initial value. ## Chain 2 Exception: normal_lpdf: Scale parameter is -0.48673, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b3e802a7a.stan&#39;, line 22, column 1 to column 34) ## Chain 2 Exception: normal_lpdf: Scale parameter is -0.48673, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b3e802a7a.stan&#39;, line 22, column 1 to column 34) ## Chain 2 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 2 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 2 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 2 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 2 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 2 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 2 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: normal_lpdf: Scale parameter is -530.687, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b3e802a7a.stan&#39;, line 22, column 1 to column 34) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: normal_lpdf: Scale parameter is -9.13345, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b3e802a7a.stan&#39;, line 22, column 1 to column 34) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 3 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 3 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 3 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 3 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: normal_lpdf: Scale parameter is -1729.7, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b3e802a7a.stan&#39;, line 22, column 1 to column 34) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 3 Exception: normal_lpdf: Scale parameter is -46.2979, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b3e802a7a.stan&#39;, line 22, column 1 to column 34) ## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 3 ## Chain 4 Rejecting initial value: ## Chain 4 Error evaluating the log probability at the initial value. ## Chain 4 Exception: normal_lpdf: Scale parameter is -1.22032, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b3e802a7a.stan&#39;, line 22, column 1 to column 34) ## Chain 4 Exception: normal_lpdf: Scale parameter is -1.22032, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b3e802a7a.stan&#39;, line 22, column 1 to column 34) ## Chain 4 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 4 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 4 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 4 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 4 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 1 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 1 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 1 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 1 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 1 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 1 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 1 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 2 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 2 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 2 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 2 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 2 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 2 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 3 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 3 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 3 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 3 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 4 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 4 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 4 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 4 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 4 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 4 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 4 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 1 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 1 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 1 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 1 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 2 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 2 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 2 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 2 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 3 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 3 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 3 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 3 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 3 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 3 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 4 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 4 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 4 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 4 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 1 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 1 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 1 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 2 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 2 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 2 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 3 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 3 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 3 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 3 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 3 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 4 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 4 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 4 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 4 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 1 finished in 0.4 seconds. ## Chain 2 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 2 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 3 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 3 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 3 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 4 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 4 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 2 finished in 0.5 seconds. ## Chain 3 finished in 0.5 seconds. ## Chain 4 finished in 0.5 seconds. ## ## All 4 chains finished successfully. ## Mean chain execution time: 0.5 seconds. ## Total execution time: 0.6 seconds. model_frogs_2_draws &lt;- cmd_draws(model_frogs_2_sample) mcmc_areas(model_frogs_2_draws, regex_pars = &#39;predation&#39;) data { int N; int survival[N]; int density[N]; int tank[N]; int size[N]; } parameters { real sigma; real alpha[N]; real alpha_bar; real beta_size; } transformed parameters { vector[N] p; for (i in 1:N) { p[i] = inv_logit(alpha[i] + beta_size * size[i]); } } model { alpha ~ normal(alpha_bar, sigma); beta_size ~ normal(0, 0.5); sigma ~ exponential(1); for (i in 1:N) { survival[i] ~ binomial(density[i], p[i]); } } # model_frogs_3_stan &lt;- &#39;model_frogs_3.stan&#39; # writeLines(readLines(model_frogs_3_stan)) # model_frogs_3 &lt;- cmdstan_model(model_frogs_3_stan, cpp_options = list(stan_threads = TRUE)) model_frogs_3_sample &lt;- model_frogs_3$sample( data = model_data, chains = 4, parallel_chains = 4, threads_per_chain = 4 ) ## Warning: &#39;threads_per_chain&#39; is set but the model was not compiled with ## &#39;cpp_options = list(stan_threads = TRUE)&#39; so &#39;threads_per_chain&#39; will have no ## effect! ## Running MCMC with 4 parallel chains... ## ## Chain 1 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 1 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 1 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 1 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: normal_lpdf: Scale parameter is -202.106, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b26061871.stan&#39;, line 22, column 1 to column 34) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: normal_lpdf: Scale parameter is -1.5052, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b26061871.stan&#39;, line 22, column 1 to column 34) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 2 Rejecting initial value: ## Chain 2 Error evaluating the log probability at the initial value. ## Chain 2 Exception: normal_lpdf: Scale parameter is -0.234149, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b26061871.stan&#39;, line 22, column 1 to column 34) ## Chain 2 Exception: normal_lpdf: Scale parameter is -0.234149, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b26061871.stan&#39;, line 22, column 1 to column 34) ## Chain 2 Rejecting initial value: ## Chain 2 Error evaluating the log probability at the initial value. ## Chain 2 Exception: normal_lpdf: Scale parameter is -1.15708, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b26061871.stan&#39;, line 22, column 1 to column 34) ## Chain 2 Exception: normal_lpdf: Scale parameter is -1.15708, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b26061871.stan&#39;, line 22, column 1 to column 34) ## Chain 2 Rejecting initial value: ## Chain 2 Error evaluating the log probability at the initial value. ## Chain 2 Exception: normal_lpdf: Scale parameter is -0.358842, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b26061871.stan&#39;, line 22, column 1 to column 34) ## Chain 2 Exception: normal_lpdf: Scale parameter is -0.358842, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b26061871.stan&#39;, line 22, column 1 to column 34) ## Chain 2 Rejecting initial value: ## Chain 2 Error evaluating the log probability at the initial value. ## Chain 2 Exception: normal_lpdf: Scale parameter is -1.09549, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b26061871.stan&#39;, line 22, column 1 to column 34) ## Chain 2 Exception: normal_lpdf: Scale parameter is -1.09549, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b26061871.stan&#39;, line 22, column 1 to column 34) ## Chain 2 Rejecting initial value: ## Chain 2 Error evaluating the log probability at the initial value. ## Chain 2 Exception: normal_lpdf: Scale parameter is -0.30469, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b26061871.stan&#39;, line 22, column 1 to column 34) ## Chain 2 Exception: normal_lpdf: Scale parameter is -0.30469, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b26061871.stan&#39;, line 22, column 1 to column 34) ## Chain 2 Rejecting initial value: ## Chain 2 Error evaluating the log probability at the initial value. ## Chain 2 Exception: normal_lpdf: Scale parameter is -0.00310604, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b26061871.stan&#39;, line 22, column 1 to column 34) ## Chain 2 Exception: normal_lpdf: Scale parameter is -0.00310604, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b26061871.stan&#39;, line 22, column 1 to column 34) ## Chain 2 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 2 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 2 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 2 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 2 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 2 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: normal_lpdf: Scale parameter is -2024.24, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b26061871.stan&#39;, line 22, column 1 to column 34) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: normal_lpdf: Scale parameter is -57.0462, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b26061871.stan&#39;, line 22, column 1 to column 34) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: normal_lpdf: Scale parameter is -0.208902, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b26061871.stan&#39;, line 22, column 1 to column 34) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 3 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 3 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 3 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 3 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 3 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 3 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 4 Rejecting initial value: ## Chain 4 Error evaluating the log probability at the initial value. ## Chain 4 Exception: normal_lpdf: Scale parameter is -1.05196, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b26061871.stan&#39;, line 22, column 1 to column 34) ## Chain 4 Exception: normal_lpdf: Scale parameter is -1.05196, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b26061871.stan&#39;, line 22, column 1 to column 34) ## Chain 4 Rejecting initial value: ## Chain 4 Error evaluating the log probability at the initial value. ## Chain 4 Exception: normal_lpdf: Scale parameter is -0.330177, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b26061871.stan&#39;, line 22, column 1 to column 34) ## Chain 4 Exception: normal_lpdf: Scale parameter is -0.330177, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b26061871.stan&#39;, line 22, column 1 to column 34) ## Chain 4 Rejecting initial value: ## Chain 4 Error evaluating the log probability at the initial value. ## Chain 4 Exception: normal_lpdf: Scale parameter is -1.48565, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b26061871.stan&#39;, line 22, column 1 to column 34) ## Chain 4 Exception: normal_lpdf: Scale parameter is -1.48565, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b26061871.stan&#39;, line 22, column 1 to column 34) ## Chain 4 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 4 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 4 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 4 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 1 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 1 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 1 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 1 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 1 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 1 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 2 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 2 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 2 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 2 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 2 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 2 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 2 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 2 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 3 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 3 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 3 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 3 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 3 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 3 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 3 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 4 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 4 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 4 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 4 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 4 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 4 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 1 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 1 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 1 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 1 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 2 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 2 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 2 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 3 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 3 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 3 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 4 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 4 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 4 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 4 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 4 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 1 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 1 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 1 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 1 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 2 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 2 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 2 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 2 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 3 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 3 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 3 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 3 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 4 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 4 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 4 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 4 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 1 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 1 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 2 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 3 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 3 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 4 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 4 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 4 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 1 finished in 0.6 seconds. ## Chain 2 finished in 0.5 seconds. ## Chain 3 finished in 0.5 seconds. ## Chain 4 finished in 0.5 seconds. ## ## All 4 chains finished successfully. ## Mean chain execution time: 0.5 seconds. ## Total execution time: 0.7 seconds. model_frogs_3_draws &lt;- cmd_draws(model_frogs_3_sample) mcmc_areas(model_frogs_3_draws, regex_pars = &#39;size&#39;) data { int N; int survival[N]; int density[N]; int tank[N]; int size[N]; int predation[N]; } parameters { real sigma; real alpha[N]; real alpha_bar; real beta_size; real beta_predation; real beta_interaction; } transformed parameters { vector[N] p; for (i in 1:N) { p[i] = inv_logit(alpha[i] + beta_size * size[i] + beta_predation * predation[i] + beta_interaction * (size[i] * predation[i])); } } model { alpha ~ normal(alpha_bar, sigma); beta_size ~ normal(0, 0.5); beta_predation ~ normal(0, 0.5); beta_interaction ~ normal(0, 0.25); sigma ~ exponential(1); for (i in 1:N) { survival[i] ~ binomial(density[i], p[i]); } } # model_frogs_4_stan &lt;- &#39;model_frogs_4.stan&#39; # writeLines(readLines(model_frogs_4_stan)) # model_frogs_4 &lt;- cmdstan_model(model_frogs_4_stan, cpp_options = list(stan_threads = TRUE)) model_frogs_4_sample &lt;- model_frogs_4$sample( data = model_data, chains = 4, parallel_chains = 4, threads_per_chain = 4 ) ## Warning: &#39;threads_per_chain&#39; is set but the model was not compiled with ## &#39;cpp_options = list(stan_threads = TRUE)&#39; so &#39;threads_per_chain&#39; will have no ## effect! ## Running MCMC with 4 parallel chains... ## Chain 1 Rejecting initial value: ## Chain 1 Error evaluating the log probability at the initial value. ## Chain 1 Exception: normal_lpdf: Scale parameter is -1.71381, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b64d5af84.stan&#39;, line 25, column 1 to column 34) ## Chain 1 Exception: normal_lpdf: Scale parameter is -1.71381, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b64d5af84.stan&#39;, line 25, column 1 to column 34) ## Chain 1 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 1 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 2 Rejecting initial value: ## Chain 2 Error evaluating the log probability at the initial value. ## Chain 2 Exception: normal_lpdf: Scale parameter is -0.602845, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b64d5af84.stan&#39;, line 25, column 1 to column 34) ## Chain 2 Exception: normal_lpdf: Scale parameter is -0.602845, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b64d5af84.stan&#39;, line 25, column 1 to column 34) ## Chain 2 Rejecting initial value: ## Chain 2 Error evaluating the log probability at the initial value. ## Chain 2 Exception: normal_lpdf: Scale parameter is -1.07431, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b64d5af84.stan&#39;, line 25, column 1 to column 34) ## Chain 2 Exception: normal_lpdf: Scale parameter is -1.07431, but must be positive! (in &#39;/tmp/Rtmpyit6q5/model-a72b64d5af84.stan&#39;, line 25, column 1 to column 34) ## Chain 2 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 2 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 3 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 3 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 4 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 4 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 1 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 1 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 1 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 2 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 2 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 2 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 3 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 4 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 4 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 1 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 1 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 1 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 2 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 2 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 2 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 3 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 3 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 4 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 4 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 1 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 1 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 1 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 2 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 2 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 2 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 2 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 3 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 3 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 3 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 3 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 4 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 4 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 4 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 4 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 1 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 1 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 2 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 2 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 2 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 3 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 3 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 3 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 3 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 4 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 4 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 4 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 1 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 1 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 1 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 2 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 2 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 3 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 3 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 3 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 4 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 4 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 1 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 1 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 1 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 2 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 2 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 2 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 3 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 3 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 4 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 4 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 4 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 1 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 2 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 2 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 3 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 3 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 3 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 4 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 4 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 1 finished in 0.8 seconds. ## Chain 2 finished in 0.9 seconds. ## Chain 3 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 4 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 4 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 3 finished in 0.9 seconds. ## Chain 4 finished in 0.9 seconds. ## ## All 4 chains finished successfully. ## Mean chain execution time: 0.9 seconds. ## Total execution time: 1.0 seconds. model_frogs_4_draws &lt;- cmd_draws(model_frogs_4_sample) mcmc_areas(model_frogs_4_draws, regex_pars = &#39;beta&#39;) Negative influence of predation is somewhat balanced by size of tank. 9.2 Question 2 In 1980, a typical Bengali woman could have 5 or more children in her lifetime. By the year 2000, a typical Bengali woman had only 2 or 3. You’re going to look at a historical set of data, when contraception was widely available but many families chose not to use it. These data reside in data(bangladesh) and come from the 1988 Bangladesh Fertility Survey. Each row is one of 1934 women. There are six variables, but you can focus on two of them for this practice problem: (1) district: ID number of administrative district each woman resided in (2) use.contraception: An indicator (0/1) of whether the woman was using contraception. data(bangladesh) DT &lt;- data.table(bangladesh) precis(DT) ## mean sd 5.5% 94.5% histogram ## woman 967.5000 558.44 107 1828 ▇▇▇▇▇▇▇▇▇▅ ## district 29.3537 17.96 1 58 ▇▅▇▅▅▇▅▃▅▅▃▅▁ ## use.contraception 0.3925 0.49 0 1 ▇▁▁▁▁▁▁▁▁▅ ## living.children 2.6520 1.24 1 4 ▅▃▁▃▁▇ ## age.centered 0.0022 9.01 -13 16 ▅▇▇▅▃▃▂ ## urban 0.2906 0.45 0 1 ▇▁▁▁▁▁▁▁▁▃ DT[, id := as.integer(woman)] DT[, district := as.integer(as.factor(district))] model_data &lt;- c(as.list(DT), N = DT[, .N]) Now, focus on predicting use.contraception, clustered by district_id. Fit both (1) a traditional fixed-effects model that uses an index variable for district and (2) a multilevel model with varying intercepts for district. Plot the predicted proportions of women in each district using contraception, for both the fixed-effects model and the varying-effects model. That is, make a plot in which district ID is on the horizontal axis and expected proportion using contraception is on the vertical.Make one plot for each model, or layer them on the same plot, as you prefer. How do the models disagree? Can you explain the pattern of disagreement? In particular, can you explain the most extreme cases of disagreement, both why they happen where they do and why the models reach different inferences? "],["lecture-01.html", "10 Lecture 01 10.1 Hypotheses - Process Models - Statistical Models 10.2 Small world / large world 10.3 Example: four marbles 10.4 Building a model", " 10 Lecture 01 10.0.1 Popper generate meaningful (not null) hypotheses and predictions and falsify those 10.0.2 Approach A framework for developing + using statistical golems Bayesian data analysis uses probability to describe uncertainty “count all the ways data can happen, according to assumptions and the assumptions with more ways consistent with the data are more plausible” Multilevel models Models within models Avoids averaging … Model comparison Compare meaningful (not null) models Caution: over fitting 10.1 Hypotheses - Process Models - Statistical Models Any statistical model M can correspond to multiple process models Any hypothesis H may correspond to multiple process models Any statistical model may correspond to multiple hypothesis Untitled 10.2 Small world / large world Small world: models have assumptions, Bayesian models fit optimally Large world: real world, no guarantee of optimality 10.3 Example: four marbles Setup 4 marbles, either black or white, with replacement Possibilities (5) therefore: WWWW, BWWW, BBWW, BBBW, BBBB Observation: BWB Calculate Given 3 observations, there are 4 choices, for a total of 64 possibilities Given we observed both a white and a black marble, possibilities WWWW and BBBB are not valid At each branch, there are 3 possibilities it can be white and 1 possibility it can be black Bayesian is additive, at each branch just sum the possibility BWWW: 3 = 1 * 3 * 1 BBWW: 8 = 2 * 2 * 2 BBBW: 9 = 3 * 1 * 3 Using new information New information is directly integrated into the old information, therefore just multiply it through So if we take another measure of B, multiply the property through BWWW: 3 * 1 = 3 BBWW: 8 * 2 = 16 BBBW: 9 * 3 = 27 Using other information Factory says B measures are rare, but minimum of 1 per bag Factory info WWWW 0 since we observed a B BWWW: 3 BBWW: 2 BBBW: 1 BBBB 0 since we observed a W Multiply it through BWWW: 3 * 3 = 9 BBWW: 16 * 2 = 32 BBBW: 1 * 27 = 27 Counts get huge - therefore we normalize them giving us probabilities (0-1) Probability theory is just normalized counting 10.4 Building a model Design the model Condition on the data Evaluate, critique the model (Restart) "],["lecture-02.html", "11 Lecture 02 11.1 Joint prior distribution 11.2 Example: inflatable world 11.3 Grid approximation", " 11 Lecture 02 11.1 Joint prior distribution The joint prior distribution is the prior probability of distribution + parameters 11.2 Example: inflatable world 11.2.1 Design the model p: water proportion 1-p: land proportion 11.2.2 Condition Bayes updating: converts priors to posteriors Adds all data at once All posteriors are the prior for next observation Sample size is embodied in the posterior 11.2.3 Evaluate Golem must be supervised Did it malfunction? Does the answer make sense? … 11.2.4 Define parameters N: fixed by experimenter W: a probability distribution, in this case a binomial distribution WLWWLWWLW dbinom(6, size = 9, prob = 0.5) p: prior probability distribution, in this case uniformed 11.2.5 Joint model W ~ Binomial(N, p) p ~ Uniform(0, 1) (W is distributed binomially with probability p on each measure, p is uniform at 1) 11.2.6 Posterior Posterior = (probability observed variables * prior) / normalizing constant (If priors are uniform, they don’t affect the shape of the posterior. They may influence the shape though) 11.3 Grid approximation Grid approximation: consider only a finite discrete set of solutions For example, 1000 solutions Generate a sequence of solutions seq_sol &lt;- seq(0, 1, length.out = 1000) Prior = uniform 1 across sequence of solutions prior &lt;- rep(1, seq_sol) Probability of data = binomial prob_data &lt;- dbinom(6, size = 9, prob = seq_sol) Posterior numerator = posterior_num &lt;- prior * prob_data Posterior standardized = posterior_numerator / sum(posterior_num) 11.3.1 Sampling from the posterior Approximate the posterior, then you can sample from the posteriors sample(p, prob = posterior, 1e4, replace = TRUE) Summarize above/below some value Percentile interval Highest posterior density interval … Predictive checks rbinorm(1e4, size = 0, prob = samples) … "],["lecture-03.html", "12 Lecture 03 12.1 Regressions 12.2 Normal distributions 12.3 Prior predictive distributions 12.4 Quadratic approximate 12.5 Centering variables", " 12 Lecture 03 12.1 Regressions Model of mean and variance of some normally distributed measure Mean as additive combination of weighted variables Typical assumed constant variable (???) The line returned is the mean - but with Bayesian we want to see the distribution of lines, ranked by plausibility The model endorses the line, but the line doesn’t necessarily fit the data In regressions there will always be more certainty at the means and bow tie towards the limits of the data Regression models don’t have arrows like DAGs - they just measure associations. 12.2 Normal distributions Normal distributions arise when repeated fluctuations tend to cancel near 0 The Gaussian distribution is the most conservative distribution to use for a prior, it is the best option if no additional scientific information is available 12.3 Prior predictive distributions Simulate from the joint posterior distribution and evaluate Setup model with quap prior &lt;- extract.prior(model) link(model, post = prior, data = seq) where the seq is a sequence of your x variable (eg for standardize -2, 2 Plot lines These are all the possibility give the prior, not the data If the lines show such a limited relationship that you’d expect that the true relationship is outside of these, expand the priors. If alternatively they are widely implausible, tighten the priors. 12.4 Quadratic approximate In a multidimensional space, QUAP uses gradient climbing to find peaks Maximum likelihood estimation = QUAP with flat priors Function in rethinking is rethinking::quap 12.5 Centering variables x - mean(x) Should be default behavior when doing a regression "],["lecture-04.html", "13 Lecture 04 13.1 Standardizing variables 13.2 Plotting uncertainty - sample from posterior 13.3 Polynomials 13.4 Splines 13.5 Basis splines", " 13 Lecture 04 13.1 Standardizing variables (x - mean(x)) / sd(x) or scale(x) Result = mean of 0, sd of 1 Helps software fit Value = 1 is equal to 1 SD 13.2 Plotting uncertainty - sample from posterior (if multivariate normal) Approximate posterior from mean, standard deviation Sample from multivariate normal distribution of parameters Use samples to generate predictions that integrate over uncertainty extract_samples returns a, b, sigma, … and you can plot each 13.3 Polynomials Polynomials have bad behavior especially at the boundaries of the data They don’t fit locally, and are not actually flexibly. Eg. a polynomial of 3rd degree will necessarily have two turns - this has to happen irrespective of the data 13.4 Splines Locally wiggly functions, combined by interpolation Geocentric - describing relationships - not exploring them 13.5 Basis splines Bayesian B-splines = P-splines Similar to linear models but with synthetic variables \\(\\mu = \\alpha + w_{1} \\beta_{1} + + w_{2} \\beta_{2} + + w_{3} \\beta_{3} + + w_{4} \\beta_{4} + ...\\) Knots are often picked at equal intervals in data, though strategies vary At each knot, the knot’s function is at 100%, moving away from it, the neighboring functions turn on Parameters always have more uncertainty than predictions Caution: over fitting 13.5.1 Recipe Choose knots - points where spline pivots Choose degree of basis functions - how wiggly, polynomial Find posterior distribution of weights "],["lecture-05.html", "14 Lecture 05 14.1 Multiple regression models 14.2 Directed acyclic graphs (DAG) 14.3 Example: Age, marriage, divorce 14.4 Plotting multivariate posteriors 14.5 Reveal masked associations 14.6 Categorical variables", " 14 Lecture 05 14.1 Multiple regression models Why? Spurious associations Determining the value of some predictor given other predictors eg. divorce rate given marriage rate and median age at marriage. Once we know marriage rate, what is the value in knowing median age? 14.2 Directed acyclic graphs (DAG) Directed: arrows, indicating causal implications Acyclic: no loops Unlike statistical models, DAGs have causal implications eg. Median age → marriage rate → divorce rate, Median age → divorce rate 14.3 Example: Age, marriage, divorce \\(D_{i} \\sim \\text{Normal}(\\mu_{i}, \\sigma)\\) \\(\\mu_{i} = \\alpha + \\beta_{M}M_{i} + \\beta_{A}A_{i}\\) (M)arriage rate (A)ge at marriage (D)ivorce rate 14.3.1 Priors Standardize to z-scores \\(\\alpha\\) = expected value for response when all values are 0. since they are all standardized the response should be 0. Without peaking at the data, this could be hard to guess. But after standardization, it is much simpler. Slopes - use prior predictive simulation. Harder. 14.3.2 Prior predictive simulation See Prior predictive distributions 14.3.3 Interpretation Once we know median age at marriage, there is little additional value in knowing marriage rate. Once we know marriage rate, there is still value in knowing median age at marriage. If we don’t know median, it is still useful to know marriage rate, since median age at marriage is related to marriage rate. However, we don’t want to try and influence eg. policy on marriage rate, since it isn’t causal on divorce rate. 14.4 Plotting multivariate posteriors Regress predictor on other predictors Compute predictor residuals Regress outcome on residuals Side note: never analyze the residuals. 14.4.1 Posterior predictive checks Compute implied predictions for observed cases Again, regressions will always do well in the area around the mean 14.5 Reveal masked associations Sometimes association between outcome and predictor is masked by another variable This tends to arise when 2 predictors associated with the outcome have opposite effects on it 14.6 Categorical variables Two approaches: Use dummy/indicator variables Use index variables Index variables are much better 14.6.1 Dummy variable “Stand in” variable Eg. male/female column, translated to 0, 1, 0, 0, 1 where 0 female, 1 male Model: \\(h_{i} \\sim \\text{Normal}(\\mu_{i}, \\sigma)\\) \\(\\mu_{i} = \\alpha + \\beta_{M}M_{i}\\) In the case of dummy variables, alpha is the mean when M = 0 (female) and beta M is the change in mean when M = 1 (male). Result is 2 intercepts = where alpha alone is for female and alpha + beta M is intercept for males Problem: for k categories, need k-1 dummy variables and need priors for each. also, priors aren’t balanced because of alpha vs beta "],["lecture-06.html", "15 Lecture 06 15.1 Index variable 15.2 Four elemental confounds", " 15 Lecture 06 15.1 Index variable (For unordered, categorical variables) Starts at 1, counts up Same prior can be given to all Extends easily &gt; 2 eg. m &lt;- quap( alist( height ~ dnorm(mu, sigma), mu &lt;- a[sex], a[sex] ~ dnorm(178, 20), sigma ~ dunif(0, 50) ), data = d ) a[sex] and a for each sex and prior for each. directly in precis(m) too. Then you can directly calculate the difference between groups in the posteriors, no need to rerun the model post &lt;- extract.samples(m) post$diff &lt;- post$a[, 1] - post$a[, 2] precis(post) # mean # sigma 27 # a[1] 134 # a[2] 142 # diff -7.7 15.2 Four elemental confounds When inferring the relationships between X and Y… Confounds are not determined by model selection, so we use DAGs. Arrows indicate causation, and statistical information can flow either way. 15.2.1 Notes Regression models don’t have arrows like DAGs - they just measure associations. You can’t tell the difference between the fork and the path given the data alone. Remember DAGs are small world constructs. 15.2.2 The fork X ← Z → Y Z is a common cause of X and Y. Including Z will remove the relationship between X and Y. 15.2.3 The path X → Z → Y Z is along the path of X and Y, mediating the relationship. For example, the influence of treatment on plant height, where treatment has an influence on fungus. T → F → H Since the treatment influences the fungus (a post treatment measure), if we include both the treatment and the fungus, we will see no relationship of treatment on height, only fungus. (once we know fungus, what does treatment tell us - nothing). In this case, the model with both treatment and fungus tells us the relationship between them, but to properly consider the influence of treatment we need to omit fungus Therefore, understanding the relationship between T and F is important, but for determining causality of T on H, we need to omit it from that model. 15.2.4 The collider X → Z ← Y Z is common result of X and Y. X and Y are independent, if you condition on Z. Careful about statistical correlations that do not indicate causation here. 15.2.5 Steps List all paths connecting X (treatment) and Y (outcome) Classify each path as either open or closed. All paths are open unless they contain a collider. Classify each path as backdoor/front door. Backdoor paths have an arrow entering X. Condition on variables in backdoor paths to close them. "],["lecture-07.html", "16 Lecture 07 16.1 Four elemental confounds (continued) 16.2 Over fitting 16.3 Measuring model fit 16.4 Obtaining the regular features", " 16 Lecture 07 16.1 Four elemental confounds (continued) 16.1.1 Unobserved variables Careful about unmeasured variables. They can create confounds, without being directly measured. Eg. (Haunted DAG). G on C. G → P → C, G → C. But unobserved variable U creates a collider: G → P ← U → C. So including P allows the collider to distort the influence on G on C. 16.2 Over fitting Ockham’s razor: “plurality should never be posited without necessity” This isn’t sufficient, because we are usually comparing between models that are more complicated but fit the data better, and models that are less complicated but fit worse. Two major hazards: too simple, not learning enough from data (under fitting) and too complex, learning too much from data (over fitting) Goal = to learn from regular features from the sample, those that will generalize to other samples 16.3 Measuring model fit 16.3.1 R squared Common, not great \\(R_{2} = 1 - \\frac{var(residuals)}{var(outcome)}\\) “Proportion of variance explained” You can get R squared = 1 with a parameter for each data point - perfect fit. This is obviously nonsense. Therefore there’s a trap of picking models solely on their R squared because increase the parameters and you will increase the R squared. 16.4 Obtaining the regular features Regularizing priors Cross validation Information criteria "],["lecture-08.html", "17 Lecture 08 17.1 Information theory 17.2 Divergence 17.3 Estimating divergence 17.4 Regularization 17.5 Cross validation 17.6 Information criteria 17.7 Model selection 17.8 Model comparison", " 17 Lecture 08 17.1 Information theory Information: reduction in uncertainty caused by learning an outcome Therefore it’s a scale of uncertainty, and information theory is a system for deriving a metric of uncertainty Information entropy: uncertainty in a probability distribution is average the log probability of an event. Uncertainty in a distribution, “potential for surprise” entropy(p) - entropy(q) is what we are trying to minimize (where p is true, q is model) 17.2 Divergence \\(D_{KL} = \\sum p_{i} (log(p_{i}) - log(q_{i}))\\) Average difference in log probability between the model q and target p It’s asymmetrical - recall W/L ratio on Earth → Mars and reverse. Expecting few water events coming from Mars and the reverse coming from Earth Since we don’t actually know the “truth”, we can’t use this to directly measure a model But turns out - we don’t need the truth to compare two models, only their average log probability 17.3 Estimating divergence This is the gold standard for scoring models 17.3.1 Log pointwise predictive density lppd Point wise measure of average probability that the model expects the data Using the entire posterior, measures the log probability Summing the vector of lppd returns the total log probability score Larger values are better, indicating larger average accuracy 17.3.2 Deviance Deviance = lppd score * -2 Smaller values are better Note: deviance decreases with more parameters, however out of sample deviance is best in the model with the right number of parameters (simulated example) 17.4 Regularization Must always be skeptical of the sample Regularization: use informative, conservative priors to reduce over fitting (models learn less from sample). This is particularly important for small sample sizes and as a result, for multilevel models. 17.5 Cross validation Without known out of sample measures, you can estimate out of sample deviance Model with some samples left out, and average over the estimate of those samples 17.5.1 LOO Leave one out Pareto-smoothed importance sample (PSIS) loo package 17.6 Information criteria Historically: AIC, a theoretical estimate of the KL distance Assumptions of AIC include priors are flat or overwhelmed by data posterior is essentially Gaussian sample size &gt;&gt; number of parameters k 17.6.1 WAIC Widely Applicable Information Criterion Does not assume Gaussian posterior 17.6.2 Standard error Presented in rethinking::compare and available for LOO or AIC comparisons. The standard error is the approximate standard error of each WAIC. Caution: with small sample sizes, the standard error reported underestimates the uncertainty. To determine if two models can be distinguished, use the standard error of their difference (dSE). Using the compare function, you can get the @dSE slot to return a matrix of dSE for each pair of models. 17.7 Model selection Avoid model selection Score models and apply causal inference to use compare competing models to explain 17.8 Model comparison Model comparison is not causal inference Add and imagine unobserved confounds 17.8.1 Example 1: model mis-selection using WAIC Height 0 → Height 1, Treatment → Fungus → Height 1 F + T, dWAIC = 0 T, dWAIC = 41 intercept = 44 Since f is a pipe on T→F, including it confounds the model AIC does not indicate causal inference, it simply identifies the best model according to the predicted out of sample deviance Model comparison AND causal inference are important 17.8.2 Example 2: primate lifetime Body mass → lifespan, Body mass → brain size → lifespan Relationship of interest: brain size on lifespan M + B, WAIC = 217 B, WAIC = 218 M = 229 Note: when we have different parameters that return similar WAIC, it’s an invitation to poke inside! Inspecting their estimate posterior we notice that the sign of the brain mass parameter flips from negative to positive across models Another approach: since WAIC is point wise we can plot the difference in WAIC for each point across models Comparing life span on Y, and point wise difference in WAIC between the two models on X We see that the model M+B is better for some species eg. Cebus, and the simple B model is better for other species eg. Gorilla Incredible "],["lecture-09.html", "18 Lecture 09 18.1 Conditioning 18.2 Interpreting interactions 18.3 Plotting interactions", " 18 Lecture 09 18.1 Conditioning Interaction of variables on each other Dependence on the state eg. Influence of genes on phenotype depends on environment Approaches Use interacting terms (simplest) Generalized linear models Multilevel models Interactions arise wherever there is a boundary in the outcome space. All GLMs have interactions. In a DAG, an interaction looks like gene → phenotype ← environment But DAGs can’t fully tell you if it’s an interaction Before interaction terms, all variables are simply independent additive terms. 18.1.1 Example: ruggedness “Ruggedness is bad for the economy outside of Africa, but within Africa is it good” Reminder - constrain priors to possible outcome space Scale ruggedness between 0, 1 Constrain change in GDP bc evidently eg GDP x 2 would be a huge effect Keep it reasonable Options Split the data? Run two linear regressions. This means there is no statistical criteria to measure the split. We are interested in the contrast in slope, but to do that we need to use the same model. Add a categorical variable for Africa? Use alpha[id] and different estimates for each This means the slope is forced to be the same, but difference intercepts. Relationship is held constant across groups, not what we want. Interaction \\(\\mu_{i} = \\alpha_{CID[i]} + \\beta_{CID[i]}(r_{i} - \\bar{r})\\) Slope and intercept are allowed to vary for each 18.1.2 Example: tulips Tulip blooms, in varying Water and Shade \\(\\mu_{i} = \\alpha + \\beta_{W}W + \\beta_{S}S + \\beta_{W * S}W*S\\) The beta W*S variable is actually a nested linear model 18.2 Interpreting interactions Interpreting interactions is hard The influence of predictors depends upon multiple parameters and their co variation Interactions are symmetric within the data. Eg. effect of continent depends on ruggedness is the same as effect of ruggedness on continent Statistically the same We need to apply our outside knowledge and causal information 18.3 Plotting interactions Use a triptych Vary shade at -1, 0, 1 Plot bloom as response and water on x 18.3.1 Higher order interactions Caution: hard to interpret, hard to estimate "],["lecture-10.html", "19 Lecture 10 19.1 Markov Chain Monte Carlo", " 19 Lecture 10 19.1 Markov Chain Monte Carlo Reminder: Bayesian inference is about calculating the posterior. Bayesian ≠ Markov Chains 4 of the ways to compute the posterior Analytical approach (mostly impossible) Grid approximation (very intensive) Quadratic approximate (limited) MCMC (intensive) Advantages of MCMC You don’t know the posterior yet you can still visit each part of it in proportion to it’s relative probability “Sample from a distribution that we don’t know” 19.1.1 Metropolis algorithm Loop over iterations Record location Generate neighbor location proposals Move based on frequency Converges in the long run, can be used as long as proposals are symmetric 19.1.2 Metropolis Hastings Improvement on Metropolis, does not require the proposals to be symmetrical 19.1.3 Gibbs sampling More efficient version of MH 19.1.4 Hamiltonian Monte Carlo Markov Chain: No memory. Probability solely depends on current state, not past state. No storage. Monte Carlo: Random simulation (eg Monaco casino) MCMC is a numerical technique to solve for the posterior, with several advantages over Metropolis and Gibbs Metropolis and Gibbs use optimization but optimization is not a good strategy in high dimensions (see concentration of measure) Hamiltonian Monte Carlo uses a gradient to avoid the guess + check of Metropolis and Gibbs Especially in high dimensional space, acceptance rate decreases and methods take more time Hamiltonian Monte Carlo: Uses a physics simulation representing the parameter state as a particle Flicks the particle around a friction less log-posterior surface Follows curvature of the surface, so it doesn’t get stuck Uses random direction and random speed Slows as it climbs, speeds as it drops This is much more computationally intensive, but requires less steps, has much fewer rejections It’s also easier to determine if MCMC has failed 19.1.5 Tuning MCMC Step size: time the simulation is run. Increase step size = increase efficiency but overestimates curvature U Turn risk is solved by NUTS (No U Turn Sampler) Warm up phase - finding the step size to maximize acceptance rate. Default = good (half the number of samples) Runs in both directions and gives uncorrelated samples. No need to pick leap frog steps 19.1.6 Stan Stan uses NUTS 19.1.7 ulam Create list of data only what you need ulam with formulas as in quap ulam translates the formulas to Stan Builds the NUTS sampler Sampler runs Returns posterior 19.1.8 Diagnosis Neff: number of effective samples. Can be greater than the number of samples from the Markov Chan. Effective if no autocorrelation Rhat: Convergence diagnostic. 1 is good. Ratio of variance within vs ratio of variance across chains. \"Typically when you have a computational problem, often there’s a problem with your model\" 19.1.9 Checking the chain TODO: p283 "],["lecture-11.html", "20 Lecture 11 20.1 Maximum entropy 20.2 Generalized linear model 20.3 Binomial distribution", " 20 Lecture 11 Flat distributions have the highest entropy and have many more ways that they can be realized 20.1 Maximum entropy Distribution with the largest entropy is the distribution most consistent with stated assumptions For parameters: helps understand priors. What are the constraints that make a prior reasonable? For observations: way to understand likelihood Solving for the posterior = getting the distribution that is as flat as possible and consistent with data within constraints Highest entropy answer = distance to the truth is smaller 20.1.1 Distributions Constraints Maxent distribution Example Real value in interval Uniform Bird proportions Real value, finite variance Gaussian Coin flip Binary events, fixed probability Binomial Marble drawing, globe tossing Non negative real, has mean Exponential Amount of time until event 20.2 Generalized linear model Connect linear model to outcome variable Pick outcome distribution Model its parameter using links to linear models Compute posterior Extends to multivariate relationships and non-linear responses Building blocks of multilevel models Very common and widely applicable 20.2.1 Picking a distribution Mostly exponential family because all are maximum entropy interpretations and arise from natural processes Do not pick by looking at a histogram - no way an aggregate histogram of outcomes unconditional on something else is going to have a relevant distribution Just use principles. Exponential: non negative real. Lambda is a rate and the mean is 1/lambda Binomial: count events emerging from an exponential distribution Poisson: count events, low rate Gamma: sum of exponential Normal: gamma with large mean Tide prediction machine - complex “parameters” at the bottom. “Can understand models if you resist the urge to understand parameters” 20.2.2 Types of outcomes Distances and durations Exponential Gamma Counts Poisson Binomial Multinomial Geometry Monsters Ranks, ordered categories Mixtures Beta binomial Gamma-poisson Etc 20.2.3 Model parameters with a link function Yi ~ Normal(mu, sigma) mu ~ alpha + beta * X Linear regressions and only linear regressions have the same scientific units for both the outcome variable and parameters for the mean Another example - binomial Count: Y ~ Binomial(N, p) (unit is count of something) Probability: P ? alpha + beta * X (unit less) We need some function f(p) = alpha + beta * X 20.3 Binomial distribution Counts of a specific event out of n possible trials min: 0, max: n Constant expected value Maxent: binomial y ~ Binomial(n, p) count successes is distribution binomially with n trials and p probability of success 20.3.1 Link Goal is to map linear model to [0, 1] y ~ Binomial(n, p) logit(p) = alpha + beta * x logit is the log odds Given this link function, priors on the logit scale are the not same shape as priors on the probability scale Prosocial monkey example y ~ Binomial(n, p) logit(p) = alpha[actor] + beta[treatment] * Treatment precis(m) a[1] … a[7] a are the different chimps, the posterior means are on the logit scale b[1] … b[4] b are the treatments, the average log odd deviations after chimp handedness has been considered Investigating extract samples inv_logit to transform to probability score precis It’s really hard to understand just using the precis output therefore Plot on the outcome scale with link = posterior predictive sampling Controlling for handedness here isn’t because of the backdoor criterion. Handedness = noise, controlling for it gives us a more precise criteria "],["lecture-12.html", "21 Lecture 12 21.1 Relative and absolute effects 21.2 Logistic regression 21.3 Simpsons paradox", " 21 Lecture 12 21.1 Relative and absolute effects Effect sizes two ways Relative effect scale: parameters have relative differences in their effect Absolute effect scale: used for predictions Proportional odds eg treatment 4 and 2 post ← extract.samples mean 0.9 = 90% of previous odds Therefore 2→4 expects reduction of odds by 10% But this disregards base rate Risk of relative effects like proportional odds is they don’t consider absolute likelihood Relative shark vs absolute deer - need both 21.2 Logistic regression 0, 1 trials (Bernoulli trials) Aggregate binomial: aggregated from each 0, 1 to counts for each category Example - UC Berkeley 1970s Gender → Department → Acceptance, Gender → Acceptance Recall: regressions are very literal to exactly the question you are asking Model 1 Acceptance ~ Binomial(N, p) logit(p) = alpha [gender] Statistical question: what are the average probabilities of admission by gender across all departments? Causal question: what is the total causal influence of gender? It’s asking for the total effect, not the discrimination effect Therefore, all paths are in play (Gender → Department → Acceptance, Gender → Acceptance) Model 2 Close the backdoor. Acceptance ~ Binomial(N, p) logit(p) = alpha [gender] + beta department Statistical question: what is the average difference in probability of admission for genders within department? Causal question: what is the direct influence of gender? These are equally valid, but different questions. 21.3 Simpsons paradox Flip of covariates sign when adding/removing a variable "],["lecture-13.html", "22 Lecture 13 22.1 Binomial 22.2 Poisson 22.3 Generalized linear madness 22.4 Scientific model 22.5 Survival analysis 22.6 Monsters 22.7 Mixtures", " 22 Lecture 13 22.1 Binomial Outcome is a count from zero to some known upper bound 22.2 Poisson Binomial events with N trials large/unknown and probability of event is small Poisson with varied exposure/offset 22.3 Generalized linear madness Example of oceanic tool complexity Modeled with a poisson link The model outcomes are terrible - though they fit the data, the intercepts don’t pass through origin Wouldn’t we expect zero population = zero tools? Solution is a scientific model 22.4 Scientific model The relationship can be thought of as a change in tools per unit time Change in time = alpha P ^ beta Alpha: innovation rate, P: population per person = each person has some change of inventing something Beta: diminishing returns, saturation effect, “someone else will invent it for you” TODO: read more about this, highlight it, etc The resulting model using this function based in the scientific model is not perfect, but meanings are clearer, the intercept actually goes through 0 This is an ad hoc function, not a link 22.5 Survival analysis Estimate rates by modeling time-to-event Can’t ignore censored cases Left censored: don’t when when time started Right censored: something else cut off end Example cats Time to adoption for observed adoptions is simplest, an exponential function For censored cats use the cumulative distribution take the complement calculate probability no event yet 22.6 Monsters Specialized complex distributions eg. ordered categories, ranks 22.7 Mixtures Blends of stochastic processes eg. varying means, probabilities, rates eg. zero-inflation, hurdles Example monks Number of manuscripts per day Can we infer the number of days they get drunk? Drunkenness is a hidden state There is a probability that they drink or work, and within the work, a probability that they produce 0 or 1+ manuscripts "],["lecture-14.html", "23 Lecture 14 23.1 Ordered categories", " 23 Lecture 14 23.1 Ordered categories Discrete outcomes with defined order, defined min and max But the “distances” between categories is unknown and not metric Hard to model because it isn’t continuous and bounded by min-max but not a count. Solution: use a log-cumulative-odds link probability model TODO fill "],["lecture-15.html", "24 Lecture 15 24.1 Multilevel models 24.2 Varying intercepts 24.3 Shrinkage 24.4 Pooling", " 24 Lecture 15 24.1 Multilevel models Most models forget things about the data as they move from one case to the other Fixed effects: the model forgets everything between clusters. no information is passed between clusters. Multilevel model: remember and pool information Default should be multilevel modeling nearly every case is improved by multilevel modeling if not, it’s just as good Why use multilevel modeling? deal with clustering in data (eg. classroom within schools, students within classrooms, …) handles imbalance in sampling handles pseudo replications 24.2 Varying intercepts Example tadpole Outcome: number surviving Tadpoles in tanks at different densities Model 1 index for each tank Model 2 multilevel with varying intercepts Untitled Varying intercepts = random intercepts “Random” and “varying” unclear Distinction of varying intercepts is the prior learns from the data Adaptive regularization From the example, survival across tanks has some distribution. This distribution is the prior for each tank. And the distribution needs its own prior 24.3 Shrinkage Model doesn’t retrodict samples exactly Shrinkage towards the population mean caused by regularization Larger variation = more shrinkage Less data per cluster = more shrinkage Increased difference from mean = more shrinkage 24.4 Pooling Why are varying effects more accurate than fixed effects? Grand mean - maximum under fitting - complete pooling Fixed effects - maximum over fitting - no pooling Varying effects - adaptive regularization - partial pooling "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
