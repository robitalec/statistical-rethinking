---
author: "Alec L. Robitaille"
output: github_document
editor_options: 
  chunk_output_type: console
---

# Homework: Week 4 
2021-08-30 [updated: `r Sys.Date()`]

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rethinking)
options(digits = 2, scipen = 999)
```

### Setup

```{r}
# Packages
library(ggdag)
library(dagitty)
library(data.table)
library(ggplot2)
library(tidybayes)
```



## Question 1
> Consider three fictional Polynesian islands. On each there is a Royal
Ornithologist charged by the king with surveying the birb population. They have
each found the following proportions of 5 important birb species:

```{r}
# Data
birds <- matrix(
	c(0.2, 0.2, 0.2, 0.2, 0.2,
		0.8, 0.1, 0.05, 0.025, 0.025,
		0.05, 0.15, 0.7, 0.05, 0.05),
	nrow = 3, ncol = 5, byrow = TRUE
)
dimnames(birds) <- list(as.character(1:3), LETTERS[1:5])
birds
```

> First, compute the entropy of each islandâ€™s birb distribution. Interpret these
entropy values

```{r}
DT <- melt(data.table(birds, keep.rownames = 'island'), id.vars = 'island',
					 variable.name = 'id', value.name = 'proportion')

# Entropy
entropy <- function(p) -sum(p * log(p))
DT[, .(entropy = entropy(proportion)), by = island]
```

The information entropy describes the uncertainty in a distribution of 
probabilities given the average log-probability of an event (from Statistical
Rethinking 7.2). Island 1 has the highest entropy, with the flat probability of 0.2 across 5 bird species. Island 2 has the lowest entropy, including species A with the highest overall proportion 0.8.


```{r}
divergence <- function(p, q) sum(p * (log(p) - log(q)))
z <- CJ(DT$island, DT$island, unique = TRUE)[, row_id := .I]
div <- z[, divergence(DT[island == V2, proportion], 
											DT[island == V1, proportion]), 
				 by = row_id]

matrix(div$V1, ncol = 3, nrow = 3, byrow = TRUE)
```
