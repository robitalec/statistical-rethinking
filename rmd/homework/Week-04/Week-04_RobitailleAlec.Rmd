---
author: "Alec L. Robitaille"
output: github_document
editor_options: 
  chunk_output_type: console
---

# Homework: Week 4 
2021-08-30 [updated: `r Sys.Date()`]

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rethinking)
options(digits = 2, scipen = 999)
```

### Setup

```{r}
# Packages
library(ggdag)
library(dagitty)
library(data.table)
library(ggplot2)
library(tidybayes)

# Functions
dag_plot <- function(dag) {
	stat <- node_status(dag, FALSE)
	stat$data$status[is.na(stat$data$status)] <- 'intermediate'
	ggplot(stat, aes(x = x, y = y, xend = xend, yend = yend)) +
	  geom_dag_point(aes(color = status), alpha = 0.5, size = 15) +
	  geom_dag_edges() +
		labs(color = '') + 
	  geom_dag_text(color = 'black') +
		scale_color_manual(values = list('exposure' = '#35608DFF',
																		 'outcome' = '#22A884FF',
																		 'intermediate' = 'grey50')) + 
	  theme_void()
}
```



## Question 1
> Consider three fictional Polynesian islands. On each there is a Royal
Ornithologist charged by the king with surveying the birb population. They have
each found the following proportions of 5 important birb species:

```{r}
# Data
birds <- matrix(
	c(0.2, 0.2, 0.2, 0.2, 0.2,
		0.8, 0.1, 0.05, 0.025, 0.025,
		0.05, 0.15, 0.7, 0.05, 0.05),
	nrow = 3, ncol = 5, byrow = TRUE
)
dimnames(birds) <- list(as.character(1:3), LETTERS[1:5])
birds
```

> First, compute the entropy of each island’s birb distribution. Interpret these
entropy values

```{r}
DT <- melt(data.table(birds, keep.rownames = 'island'), id.vars = 'island',
					 variable.name = 'id', value.name = 'proportion')

# Entropy
entropy <- function(p) -sum(p * log(p))
DT[, .(entropy = entropy(proportion)), by = island]
```

The information entropy describes the uncertainty in a distribution of 
probabilities given the average log-probability of an event (from Statistical
Rethinking 7.2). Island 1 has the highest entropy, with the flat probability of 0.2 across 5 bird species. Island 2 has the lowest entropy, including species A with the highest overall proportion 0.8.


> Second, use each island’s birb distribution to predict the other two. This
means to compute the K-L Divergence of each island from the others, treating
each island as if it were a statistical model of the other islands. You should
end up with 6 different K-L Divergence values. Which island predicts the others
best? Why?


```{r}
divergence <- function(p, q) sum(p * (log(p) - log(q)))
z <- CJ(p = DT$island, q = DT$island, unique = TRUE)[, row_id := .I]
z[, div := divergence(DT[island == p, proportion], 
											DT[island == q, proportion]),
	by = row_id]

z[p != q]
```


`divergence(p, q)` = "Average difference in log probability between the target (p) and the model (q)". 


Model 1 predicts target 3 best (lowest divergence at 0.63) and target 2 best (lowest divergence at 0.87) because it has the highest entropy. Model 3 predicts target 1 best (lowest divergence at 0.64) because it has higher entropy than model 2. 


## Question 2 

> Recall the marriage, age, and happiness collider bias example from Chapter
6. Run models m6.9 and m6.10 again. 


### DAG
```{r}
dag <- dagify(
	marriage ~ happiness,
	marriage ~ age,
	exposure = 'age',
	outcome = 'happiness'
)

dag_plot(dag)
```

### Data
```{r}
library(rethinking)
d <- sim_happiness(seed = 1977, N_years = 1e3)

d2 <- d[d$age > 17,]
d2$A <- (d2$age - 18) / (65 - 18)
d2$mid <- d2$married + 1

precis(d2)
```

### Models

```{r}
m6.9 <- quap(
	alist(
		happiness ~ dnorm(mu, sigma),
		mu <- a[mid] + bA * A,
		a[mid] ~ dnorm(0, 1),
		bA ~ dnorm(0, 2),
		sigma ~ dexp(1)
	), data = d2
)

precis(m6.9, depth = 2)
```


```{r}
m6.10 <- quap(
	alist(
		happiness ~ dnorm(mu, sigma),
		mu <- a + bA * A,
		a ~ dnorm(0, 1),
		bA ~ dnorm(0, 2),
		sigma ~ dexp(1)
	), data = d2
)

precis(m6.10, depth = 2)
```

### Interpretation

> Compare these two models using WAIC (or LOO, they will produce identical
results). Which model is expected to make better predictions? Which model
provides the correct causal inference about the influence of age on happiness?
Can you explain why the answers to these two questions disagree?


```{r, eval = FALSE}
compare(m6.9, m6.10)
```

```{r, echo = FALSE}
round(compare(m6.9, m6.10), 2)
```


Model m6.9 includes marriage while m6.10 does not. The causal influence of age
on happiness is confounded by marriage because marriage is a collider between
age and happiness. Conditioning on marriage opens the path between age and
happiness, making age and happiness independent. Therefore, despite the WAIC for
m6.9 being lower, it does not tell us anything about causation between the
variables.


## Question 3

> Reconsider the urban fox analysis from last week’s homework. Use WAIC or LOO
based model comparison on five different models, each using weight as the
outcome, and containing these sets of predictor variables:

1. avgfood + groupsize + area
2. avgfood + groupsize
3. groupsize + area
4. avgfood
5. area


### Data
```{r}
library(rethinking)

data(foxes)
```


### Models

```{r}
foxes$scale_area <- scale(foxes$area)
foxes$scale_weight <- scale(foxes$weight)
foxes$scale_avgfood <- scale(foxes$avgfood)
foxes$scale_groupsize <- scale(foxes$groupsize)

m1 <- quap(
	alist(
		scale_weight ~ dnorm(mu, sigma),
		mu <- a + bFood * scale_avgfood + bGroup * scale_groupsize + bArea * scale_area,
		a ~ dnorm(0, 0.2),
		bFood ~ dnorm(0, 0.5),
		bGroup ~ dnorm(0, 0.5),
		bArea ~ dnorm(0, 0.5),
		sigma ~ dunif(0, 50)
	), 
	data = foxes
)

m2 <- quap(
	alist(
		scale_weight ~ dnorm(mu, sigma),
		mu <- a + bFood * scale_avgfood + bGroup * scale_groupsize,
		a ~ dnorm(0, 0.2),
		bFood ~ dnorm(0, 0.5),
		bGroup ~ dnorm(0, 0.5),
		sigma ~ dunif(0, 50)
	), 
	data = foxes
)

m3 <- quap(
	alist(
		scale_weight ~ dnorm(mu, sigma),
		mu <- a + bGroup * scale_groupsize + bArea * scale_area,
		a ~ dnorm(0, 0.2),
		bArea ~ dnorm(0, 0.5),
		bGroup ~ dnorm(0, 0.5),
		sigma ~ dunif(0, 50)
	), 
	data = foxes
)

m4 <- quap(
	alist(
		scale_weight ~ dnorm(mu, sigma),
		mu <- a + bFood * scale_avgfood,
		a ~ dnorm(0, 0.2),
		bFood ~ dnorm(0, 0.5),
		sigma ~ dunif(0, 50)
	), 
	data = foxes
)

m5 <- quap(
	alist(
		scale_weight ~ dnorm(mu, sigma),
		mu <- a + bArea * scale_area,
		a ~ dnorm(0, 0.2),
		bArea ~ dnorm(0, 0.5),
		sigma ~ dunif(0, 50)
	), 
	data = foxes
)
```


### DAG
```{r}
dag <- dagify(
	weight ~ groupsize + avgfood,
	groupsize ~ avgfood,
	avgfood ~ area,
	exposure = 'area',
	outcome = 'weight'
)

dag_plot(dag)
```

### Interpretation

> Can you explain the relative differences in WAIC scores, using the fox DAG
from last week’s homework? Be sure to pay attention to the standard error of the
score differences (dSE).

1. weight ~ avgfood + groupsize + area
2. weight ~ avgfood + groupsize
3. weight ~ groupsize + area
4. weight ~ avgfood
5. weight ~ area

```{r}
compare_models <- compare(m1, m2, m3, m4, m5)
compare_models

compare_models@dSE

plot(compare_models)
```

Weight is the outcome in all of the models. Looking at the DAG, we see a potential back door into avgfood and group size, but no colliders. Avgfood is a path between area and weight, as is groupsize between avgfood and weight. Model 1 includes the most parameters and, as expected, has the highest model fit. 
